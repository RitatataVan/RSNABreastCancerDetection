{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#https://www.kaggle.com/datasets/canming/rsna-tfrecords-768x1344-dataset2\n","#https://www.kaggle.com/datasets/markwijkhuizen/keras-cv-attention-models\n","#https://www.kaggle.com/competitions/rsna-breast-cancer-detection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:51:57.414576Z","iopub.status.busy":"2023-01-25T18:51:57.414272Z","iopub.status.idle":"2023-01-25T18:52:06.278282Z","shell.execute_reply":"2023-01-25T18:52:06.277519Z","shell.execute_reply.started":"2023-01-25T18:51:57.414501Z"},"trusted":true},"outputs":[],"source":["# Install ConvNextV2 Models From Keras CV Attention Models Pip Package\n","!pip install -qq /kaggle/input/keras-cv-attention-models/keras_cv_attention_models-1.3.9-py3-none-any.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z"},"trusted":true},"outputs":[],"source":["%%writefile convext_m0.py\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from tqdm.notebook import tqdm\n","from multiprocessing import cpu_count\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import train_test_split\n","from keras_cv_attention_models import convnext\n","\n","import os\n","import time\n","import pickle\n","import math\n","import random\n","import sys\n","import cv2\n","import gc\n","import datetime\n","\n","print(f'Tensorflow Version: {tf.__version__}')\n","print(f'Python Version: {sys.version}')\n","\n","# Save Versions\n","\n","now = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n","np.save(now, np.array([now]))\n","\n","# Mixed Precision Policy\n","\n","# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n","# TPU is fast enough and has enough memory to use float32\n","policy = tf.keras.mixed_precision.Policy('float32')\n","tf.keras.mixed_precision.set_global_policy(policy)\n","\n","print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","\n","# Matplotlib Config\n","\n","# MatplotLib Global Settings\n","mpl.rcParams.update(mpl.rcParamsDefault)\n","mpl.rcParams['xtick.labelsize'] = 16\n","mpl.rcParams['ytick.labelsize'] = 16\n","mpl.rcParams['axes.labelsize'] = 18\n","mpl.rcParams['axes.titlesize'] = 24\n","\n","# Config\n","\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","    print('Running on TPU ', TPU.master())\n","except ValueError:\n","    print('Running on GPU')\n","    TPU = None\n","\n","if TPU:\n","    IS_TPU = True\n","    tf.config.experimental_connect_to_cluster(TPU)\n","    tf.tpu.experimental.initialize_tpu_system(TPU)\n","    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n","else:\n","    IS_TPU = False\n","    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","N_REPLICAS = STRATEGY.num_replicas_in_sync\n","print(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n","\n","#/kaggle/input/rsna-tfrecords-768x1344-dataset\n","\n","# For TPU's the dataset needs to be stored in Google Cloud\n","# Retrieve the Google Cloud location of the dataset\n","GCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n","\n","SEED = 43\n","DEBUG = False\n","VERSION = 'convext_m0'\n","# Image dimensions\n","IMG_HEIGHT = 1344\n","IMG_WIDTH = 768\n","N_CHANNELS = 1\n","INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\n","N_SAMPLES_TFRECORDS = 548\n","\n","# Peak Learning Rate\n","LR_MAX = 5e-6 * N_REPLICAS\n","WD_RATIO = 0.008\n","\n","N_WARMUP_EPOCHS = 0\n","N_EPOCHS = 10\n","\n","# Batch size\n","BATCH_SIZE = 8 * N_REPLICAS\n","\n","# Is Interactive Flag and COrresponding Verbosity Method\n","IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","VERBOSE = 1 if IS_INTERACTIVE else 2\n","\n","# Tensorflow AUTO flag\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","print(f'BATCH_SIZE: {BATCH_SIZE}')\n","\n","# Seed\n","\n","# Seed all random number generators\n","def seed_everything(seed=SEED):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything()\n","\n","# Train\n","\n","# Train DataFrame\n","train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n","\n","\n","# Utility Functions\n","\n","# short Tensorflow randin integer function\n","def tf_rand_int(minval, maxval, dtype=tf.int64):\n","    minval = tf.cast(minval, dtype)\n","    maxval = tf.cast(maxval, dtype)\n","    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n","\n","# chance of 1 in k\n","def one_in(k):\n","    return 0 == tf_rand_int(0, k)\n","\n","# Dataset\n","\n","# Function to benchmark the dataset\n","def benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n","    start_time = time.perf_counter()\n","    for epoch_num in range(num_epochs):\n","        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n","            if idx == 0:\n","                epoch_start = time.perf_counter()\n","            elif idx == 1 and epoch_num == 0:\n","                image = inputs['image']\n","                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n","            else:\n","                pass\n","        \n","        epoch_t = time.perf_counter() - epoch_start\n","        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n","        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n","        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n","\n","# Plots a batch of images\n","def show_batch(dataset, n_rows=16, n_cols=4):\n","    inputs, targets = next(iter(dataset))\n","    images = inputs['image'].numpy().squeeze()\n","    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            idx = r * n_cols + c\n","            # Image\n","            img = images[idx]\n","            axes[r, c].imshow(img)\n","            # Target\n","            target = targets[idx]\n","            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n","        \n","    plt.show()\n","\n","# Decodes the TFRecords\n","def decode_image(record_bytes):\n","    features = tf.io.parse_single_example(record_bytes, {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'target': tf.io.FixedLenFeature([], tf.int64),\n","        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n","    })\n","    \n","    # Decode PNG Image\n","    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n","    # Explicit reshape needed for TPU\n","    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n","\n","    target = features['target']\n","    \n","    return { 'image': image }, target\n","\n","def augment_image(X, y):\n","    image = X['image']\n","    \n","    # Random Brightness\n","    image = tf.image.random_brightness(image, 0.10)\n","    \n","    # Random Contrast\n","    image = tf.image.random_contrast(image, 0.90, 1.10)\n","    \n","    # Random JPEG Quality\n","    image = tf.image.random_jpeg_quality(image, 75, 100)\n","    \n","    # Random crop image with maximum of 10%\n","    ratio = tf.random.uniform([], 0.75, 1.00)\n","    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n","    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n","    # Random offset for crop\n","    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n","    img_width_offset = 0\n","    # Crop And Resize\n","    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n","    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n","    # Clip pixel values in range [0,255] to prevent underflow/overflow\n","    image = tf.clip_by_value(image, 0, 255)\n","    image = tf.cast(image, tf.uint8)\n","    \n","    return { 'image': image }, y\n","\n","# Undersample majority class (0/negative) by randomly dropping them\n","def undersample_majority(X, y):\n","    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n","    return y == 1 or tf.random.uniform([]) > 0.76\n","\n","# TFRecord file paths\n","TFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\n","print(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n","\n","# Train Test Split\n","TFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","#TFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\n","#TFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL2]\n","#TFRECORDS_VAL = TFRECORDS_VAL2\n","print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","def get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False\n","    \n","    # Initialize dataset with TFRecords\n","    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n","    \n","    # Decode mapping\n","    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n","\n","    if not val:\n","        dataset = dataset.filter(undersample_majority)\n","        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n","        dataset = dataset.with_options(ignore_order)\n","        if not debug:\n","            dataset = dataset.shuffle(1024)\n","        dataset = dataset.repeat()        \n","\n","    dataset = dataset.batch(bs, drop_remainder=not val)\n","    dataset = dataset.prefetch(AUTO)\n","    \n","    return dataset\n","\n","# Get Train/Validation datasets\n","train_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\n","val_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n","\n","TRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","VAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","print(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n","\n","# Sanity check, image and label statistics\n","X_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\n","image = X_batch['image'].numpy()\n","print(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\n","print(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\n","print(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n","\n","# Benchmark Dataset\n","benchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n","\n","# Show what we will be training on\n","show_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n","\n","# Tensorflow custom metric is just a conventional class object\n","class pF1(tf.keras.metrics.Metric):\n","    # Initialize properties\n","    def __init__(self, name='pF1', **kwargs):\n","        super(pF1, self).__init__(name=name, **kwargs)\n","        self.tc = self.add_weight(name='tc', initializer='zeros')\n","        self.tp = self.add_weight(name='tp', initializer='zeros')\n","        self.fp = self.add_weight(name='fp', initializer='zeros')\n","\n","    # Update state called on each batch with true and predicted labels\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n","        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n","        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n","\n","    # Result function is called to obtain result which is printed in progress bar\n","    def result(self):\n","        if self.tc == 0 or (self.tp + self.fp) == 0:\n","            return 0.0\n","        else:\n","            precision = self.tp / (self.tp + self.fp)\n","            recall = self.tp / (self.tc)\n","            return 2 * (precision * recall) / (precision + recall)\n","\n","    # Reset state is called after each epoch to start fresh each epoch\n","    def reset_state(self):\n","        self.tc.assign(0)\n","        self.tp.assign(0)\n","        self.fp.assign(0)\n","\n","def normalize(image):\n","    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n","    image = tf.repeat(image, repeats=3, axis=3)\n","    # Cast to float 32\n","    image = tf.cast(image, tf.float32)\n","    # Normalize with respect to ImageNet mean/std\n","    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n","\n","    return image\n","\n","def get_model():\n","    # Verify Mixed Policy Settings\n","    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","    \n","    with STRATEGY.scope():\n","        # Set seed for deterministic weights initialization\n","        seed_everything()\n","        \n","        # Inputs, note the names are equal to the dictionary keys in the dataset\n","        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n","        \n","        # Normalize Input\n","        image_norm = normalize(image)\n","\n","        # CNN Prediction in range [0,1]\n","        x = convnext.ConvNeXtV2Tiny(\n","            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n","            pretrained='imagenet21k-ft1k',\n","            num_classes=0,\n","        )(image_norm)\n","        \n","        # Average Pooling BxHxWxC -> BxC\n","        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","        # Dropout to prevent Overfitting\n","        x = tf.keras.layers.Dropout(0.30)(x)\n","        # Output value between [0, 1] using Sigmoid function\n","        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","        # We will use the famous AdamW optimizer for fast learning with weight decay\n","        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n","\n","        # Loss\n","        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n","        \n","        # Metrics\n","        metrics = [\n","            pF1(),\n","            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n","            tf.keras.metrics.Precision(),\n","            tf.keras.metrics.Recall(),\n","            tf.keras.metrics.AUC(),\n","            tf.keras.metrics.BinaryAccuracy(),\n","        ]\n","\n","        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n","        \n","        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","        return model\n","\n","# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\n","tf.keras.backend.clear_session()\n","# enable XLA optmizations\n","tf.config.optimizer.set_jit(True)\n","\n","model = get_model()\n","\n","# Weight Initilization\n","\n","# Validation metric on initialized model\n","_ = model.evaluate(\n","        get_dataset(TFRECORDS_VAL, val=True),\n","        verbose=VERBOSE,\n","        steps=VAL_STEPS_PER_EPOCH,\n","    )\n","\n","# Learning rate scheduler with logaritmic warmup and cosine decay\n","def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n","    \n","    if current_step < num_warmup_steps:\n","        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n","    else:\n","        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n","\n","        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n","\n","# Plot the learning rate scheduler\n","def plot_lr_schedule(lr_schedule, epochs):\n","    fig = plt.figure(figsize=(20, 10))\n","    plt.plot([None] + lr_schedule + [None])\n","    # X Labels\n","    x = np.arange(1, epochs + 1)\n","    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n","    plt.xlim([1, epochs])\n","    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n","    \n","    # Increase y-limit for better readability\n","    plt.ylim([0, max(lr_schedule) * 1.1])\n","    \n","    # Title\n","    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n","    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n","    \n","    # Plot Learning Rates\n","    for x, val in enumerate(lr_schedule):\n","        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n","            if x < len(lr_schedule) - 1:\n","                if lr_schedule[x - 1] < val:\n","                    ha = 'right'\n","                else:\n","                    ha = 'left'\n","            elif x == 0:\n","                ha = 'right'\n","            else:\n","                ha = 'left'\n","            plt.plot(x + 1, val, 'o', color='black');\n","            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n","            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n","    \n","    plt.xlabel('Epoch', size=16, labelpad=5)\n","    plt.ylabel('Learning Rate', size=16, labelpad=5)\n","    plt.grid()\n","    plt.show()\n","\n","# Learning rate for encoder\n","LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n","plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n","\n","# Learning Rate Callback\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n","\n","# Weight Decay Callback\n","\n","# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\n","class WeightDecayCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, wd_ratio=WD_RATIO):\n","        self.step_counter = 0\n","        self.wd_ratio = wd_ratio\n","    \n","    def on_epoch_begin(self, epoch, logs=None):\n","        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n","        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n","\n","# Train model on TPU!\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=f'best_{VERSION}.h5',\n","    save_weights_only=True,\n","    monitor='val_pF1',\n","    mode='max',\n","    save_best_only=True)\n","history = model.fit(\n","        train_dataset,\n","        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n","        validation_data = val_dataset,\n","        epochs = N_EPOCHS,\n","        verbose = VERBOSE,\n","        callbacks = [\n","            model_checkpoint_callback,\n","            lr_callback,\n","            WeightDecayCallback(),\n","        ],\n","        class_weight = {\n","            0: 1.0,\n","            1: 5.0,\n","        },\n","    )\n","\n","# Save model weights for inference\n","model.save_weights(f'model_{VERSION}.h5')\n","\n","# F1 By Threshold\n","\n","# Get true labels and predictions for validation set\n","y_true_val = []\n","y_pred_val = []\n","for X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n","    y_true_val += y_batch.numpy().tolist()\n","    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n","\n","# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n","# Competition Leaderboard Metric\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","\n","# Plot pF1 by threshold plot to find best threshold\n","pf1_by_threshold = []\n","thresholds = np.arange(0, 1.01, 0.01)\n","for t in tqdm(thresholds):\n","    # Compute pF1 for each threshold\n","    pf1_by_threshold.append(\n","        pfbeta(y_true_val, y_pred_val > t)\n","    )\n","    \n","plt.figure(figsize=(15,8))\n","plt.title('F1 By Threshold', size=24)\n","plt.plot(pf1_by_threshold, label='F1 Score')\n","\n","# Best threshold and pF1 score\n","arg_max = np.argmax(pf1_by_threshold)\n","val_max = np.max(pf1_by_threshold)\n","threshold_best = thresholds[arg_max]\n","plt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n","\n","# Plot pF1 by Threshold\n","plt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\n","plt.yticks(np.arange(0, 1.1, 0.1))\n","plt.xlim(0, 100)\n","plt.ylim(0, 1)\n","plt.xlabel('Threshold')\n","plt.ylabel('pF1 Score')\n","plt.legend(fontsize=12)\n","plt.grid()\n","plt.show()\n","print(f'Best Threshold {threshold_best:.2f}.')\n","\n","print(f'pF1 Score: {val_max:.2f}.')\n","\n","# Training History"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python convext_m0.py"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z"},"trusted":true},"outputs":[],"source":["%%writefile convext_m1.py\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from tqdm.notebook import tqdm\n","from multiprocessing import cpu_count\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import train_test_split\n","from keras_cv_attention_models import convnext\n","\n","import os\n","import time\n","import pickle\n","import math\n","import random\n","import sys\n","import cv2\n","import gc\n","import datetime\n","\n","print(f'Tensorflow Version: {tf.__version__}')\n","print(f'Python Version: {sys.version}')\n","\n","# Save Versions\n","\n","now = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n","np.save(now, np.array([now]))\n","\n","# Mixed Precision Policy\n","\n","# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n","# TPU is fast enough and has enough memory to use float32\n","policy = tf.keras.mixed_precision.Policy('float32')\n","tf.keras.mixed_precision.set_global_policy(policy)\n","\n","print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","\n","# Matplotlib Config\n","\n","# MatplotLib Global Settings\n","mpl.rcParams.update(mpl.rcParamsDefault)\n","mpl.rcParams['xtick.labelsize'] = 16\n","mpl.rcParams['ytick.labelsize'] = 16\n","mpl.rcParams['axes.labelsize'] = 18\n","mpl.rcParams['axes.titlesize'] = 24\n","\n","# Config\n","\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","    print('Running on TPU ', TPU.master())\n","except ValueError:\n","    print('Running on GPU')\n","    TPU = None\n","\n","if TPU:\n","    IS_TPU = True\n","    tf.config.experimental_connect_to_cluster(TPU)\n","    tf.tpu.experimental.initialize_tpu_system(TPU)\n","    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n","else:\n","    IS_TPU = False\n","    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","N_REPLICAS = STRATEGY.num_replicas_in_sync\n","print(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n","\n","#/kaggle/input/rsna-tfrecords-768x1344-dataset\n","\n","# For TPU's the dataset needs to be stored in Google Cloud\n","# Retrieve the Google Cloud location of the dataset\n","GCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n","\n","SEED = 43\n","DEBUG = False\n","VERSION = 'convext_m1'\n","# Image dimensions\n","IMG_HEIGHT = 1344\n","IMG_WIDTH = 768\n","N_CHANNELS = 1\n","INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\n","N_SAMPLES_TFRECORDS = 548\n","\n","# Peak Learning Rate\n","LR_MAX = 5e-6 * N_REPLICAS\n","WD_RATIO = 0.008\n","\n","N_WARMUP_EPOCHS = 0\n","N_EPOCHS = 10\n","\n","# Batch size\n","BATCH_SIZE = 8 * N_REPLICAS\n","\n","# Is Interactive Flag and COrresponding Verbosity Method\n","IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","VERBOSE = 1 if IS_INTERACTIVE else 2\n","\n","# Tensorflow AUTO flag\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","print(f'BATCH_SIZE: {BATCH_SIZE}')\n","\n","# Seed\n","\n","# Seed all random number generators\n","def seed_everything(seed=SEED):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything()\n","\n","# Train\n","\n","# Train DataFrame\n","train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n","\n","\n","# Utility Functions\n","\n","# short Tensorflow randin integer function\n","def tf_rand_int(minval, maxval, dtype=tf.int64):\n","    minval = tf.cast(minval, dtype)\n","    maxval = tf.cast(maxval, dtype)\n","    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n","\n","# chance of 1 in k\n","def one_in(k):\n","    return 0 == tf_rand_int(0, k)\n","\n","# Dataset\n","\n","# Function to benchmark the dataset\n","def benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n","    start_time = time.perf_counter()\n","    for epoch_num in range(num_epochs):\n","        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n","            if idx == 0:\n","                epoch_start = time.perf_counter()\n","            elif idx == 1 and epoch_num == 0:\n","                image = inputs['image']\n","                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n","            else:\n","                pass\n","        \n","        epoch_t = time.perf_counter() - epoch_start\n","        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n","        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n","        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n","\n","# Plots a batch of images\n","def show_batch(dataset, n_rows=16, n_cols=4):\n","    inputs, targets = next(iter(dataset))\n","    images = inputs['image'].numpy().squeeze()\n","    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            idx = r * n_cols + c\n","            # Image\n","            img = images[idx]\n","            axes[r, c].imshow(img)\n","            # Target\n","            target = targets[idx]\n","            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n","        \n","    plt.show()\n","\n","# Decodes the TFRecords\n","def decode_image(record_bytes):\n","    features = tf.io.parse_single_example(record_bytes, {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'target': tf.io.FixedLenFeature([], tf.int64),\n","        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n","    })\n","    \n","    # Decode PNG Image\n","    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n","    # Explicit reshape needed for TPU\n","    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n","\n","    target = features['target']\n","    \n","    return { 'image': image }, target\n","\n","def augment_image(X, y):\n","    image = X['image']\n","    \n","    # Random Brightness\n","    image = tf.image.random_brightness(image, 0.10)\n","    \n","    # Random Contrast\n","    image = tf.image.random_contrast(image, 0.90, 1.10)\n","    \n","    # Random JPEG Quality\n","    image = tf.image.random_jpeg_quality(image, 75, 100)\n","    \n","    # Random crop image with maximum of 10%\n","    ratio = tf.random.uniform([], 0.75, 1.00)\n","    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n","    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n","    # Random offset for crop\n","    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n","    img_width_offset = 0\n","    # Crop And Resize\n","    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n","    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n","    # Clip pixel values in range [0,255] to prevent underflow/overflow\n","    image = tf.clip_by_value(image, 0, 255)\n","    image = tf.cast(image, tf.uint8)\n","    \n","    return { 'image': image }, y\n","\n","# Undersample majority class (0/negative) by randomly dropping them\n","def undersample_majority(X, y):\n","    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n","    return y == 1 or tf.random.uniform([]) > 0.76\n","\n","# TFRecord file paths\n","TFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\n","print(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n","\n","# Train Test Split\n","TFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","TFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\n","TFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL2]\n","TFRECORDS_VAL = TFRECORDS_VAL2\n","print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","def get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False\n","    \n","    # Initialize dataset with TFRecords\n","    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n","    \n","    # Decode mapping\n","    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n","\n","    if not val:\n","        dataset = dataset.filter(undersample_majority)\n","        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n","        dataset = dataset.with_options(ignore_order)\n","        if not debug:\n","            dataset = dataset.shuffle(1024)\n","        dataset = dataset.repeat()        \n","\n","    dataset = dataset.batch(bs, drop_remainder=not val)\n","    dataset = dataset.prefetch(AUTO)\n","    \n","    return dataset\n","\n","# Get Train/Validation datasets\n","train_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\n","val_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n","\n","TRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","VAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","print(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n","\n","# Sanity check, image and label statistics\n","X_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\n","image = X_batch['image'].numpy()\n","print(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\n","print(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\n","print(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n","\n","# Benchmark Dataset\n","benchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n","\n","# Show what we will be training on\n","show_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n","\n","# Tensorflow custom metric is just a conventional class object\n","class pF1(tf.keras.metrics.Metric):\n","    # Initialize properties\n","    def __init__(self, name='pF1', **kwargs):\n","        super(pF1, self).__init__(name=name, **kwargs)\n","        self.tc = self.add_weight(name='tc', initializer='zeros')\n","        self.tp = self.add_weight(name='tp', initializer='zeros')\n","        self.fp = self.add_weight(name='fp', initializer='zeros')\n","\n","    # Update state called on each batch with true and predicted labels\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n","        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n","        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n","\n","    # Result function is called to obtain result which is printed in progress bar\n","    def result(self):\n","        if self.tc == 0 or (self.tp + self.fp) == 0:\n","            return 0.0\n","        else:\n","            precision = self.tp / (self.tp + self.fp)\n","            recall = self.tp / (self.tc)\n","            return 2 * (precision * recall) / (precision + recall)\n","\n","    # Reset state is called after each epoch to start fresh each epoch\n","    def reset_state(self):\n","        self.tc.assign(0)\n","        self.tp.assign(0)\n","        self.fp.assign(0)\n","\n","def normalize(image):\n","    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n","    image = tf.repeat(image, repeats=3, axis=3)\n","    # Cast to float 32\n","    image = tf.cast(image, tf.float32)\n","    # Normalize with respect to ImageNet mean/std\n","    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n","\n","    return image\n","\n","def get_model():\n","    # Verify Mixed Policy Settings\n","    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","    \n","    with STRATEGY.scope():\n","        # Set seed for deterministic weights initialization\n","        seed_everything()\n","        \n","        # Inputs, note the names are equal to the dictionary keys in the dataset\n","        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n","        \n","        # Normalize Input\n","        image_norm = normalize(image)\n","\n","        # CNN Prediction in range [0,1]\n","        x = convnext.ConvNeXtV2Tiny(\n","            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n","            pretrained='imagenet21k-ft1k',\n","            num_classes=0,\n","        )(image_norm)\n","        \n","        # Average Pooling BxHxWxC -> BxC\n","        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","        # Dropout to prevent Overfitting\n","        x = tf.keras.layers.Dropout(0.30)(x)\n","        # Output value between [0, 1] using Sigmoid function\n","        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","        # We will use the famous AdamW optimizer for fast learning with weight decay\n","        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n","\n","        # Loss\n","        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n","        \n","        # Metrics\n","        metrics = [\n","            pF1(),\n","            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n","            tf.keras.metrics.Precision(),\n","            tf.keras.metrics.Recall(),\n","            tf.keras.metrics.AUC(),\n","            tf.keras.metrics.BinaryAccuracy(),\n","        ]\n","\n","        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n","        \n","        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","        return model\n","\n","# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\n","tf.keras.backend.clear_session()\n","# enable XLA optmizations\n","tf.config.optimizer.set_jit(True)\n","\n","model = get_model()\n","\n","# Weight Initilization\n","\n","# Validation metric on initialized model\n","_ = model.evaluate(\n","        get_dataset(TFRECORDS_VAL, val=True),\n","        verbose=VERBOSE,\n","        steps=VAL_STEPS_PER_EPOCH,\n","    )\n","\n","# Learning rate scheduler with logaritmic warmup and cosine decay\n","def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n","    \n","    if current_step < num_warmup_steps:\n","        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n","    else:\n","        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n","\n","        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n","\n","# Plot the learning rate scheduler\n","def plot_lr_schedule(lr_schedule, epochs):\n","    fig = plt.figure(figsize=(20, 10))\n","    plt.plot([None] + lr_schedule + [None])\n","    # X Labels\n","    x = np.arange(1, epochs + 1)\n","    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n","    plt.xlim([1, epochs])\n","    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n","    \n","    # Increase y-limit for better readability\n","    plt.ylim([0, max(lr_schedule) * 1.1])\n","    \n","    # Title\n","    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n","    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n","    \n","    # Plot Learning Rates\n","    for x, val in enumerate(lr_schedule):\n","        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n","            if x < len(lr_schedule) - 1:\n","                if lr_schedule[x - 1] < val:\n","                    ha = 'right'\n","                else:\n","                    ha = 'left'\n","            elif x == 0:\n","                ha = 'right'\n","            else:\n","                ha = 'left'\n","            plt.plot(x + 1, val, 'o', color='black');\n","            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n","            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n","    \n","    plt.xlabel('Epoch', size=16, labelpad=5)\n","    plt.ylabel('Learning Rate', size=16, labelpad=5)\n","    plt.grid()\n","    plt.show()\n","\n","# Learning rate for encoder\n","LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n","plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n","\n","# Learning Rate Callback\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n","\n","# Weight Decay Callback\n","\n","# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\n","class WeightDecayCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, wd_ratio=WD_RATIO):\n","        self.step_counter = 0\n","        self.wd_ratio = wd_ratio\n","    \n","    def on_epoch_begin(self, epoch, logs=None):\n","        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n","        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n","\n","# Train model on TPU!\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=f'best_{VERSION}.h5',\n","    save_weights_only=True,\n","    monitor='val_pF1',\n","    mode='max',\n","    save_best_only=True)\n","history = model.fit(\n","        train_dataset,\n","        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n","        validation_data = val_dataset,\n","        epochs = N_EPOCHS,\n","        verbose = VERBOSE,\n","        callbacks = [\n","            model_checkpoint_callback,\n","            lr_callback,\n","            WeightDecayCallback(),\n","        ],\n","        class_weight = {\n","            0: 1.0,\n","            1: 5.0,\n","        },\n","    )\n","\n","# Save model weights for inference\n","model.save_weights(f'model_{VERSION}.h5')\n","\n","# F1 By Threshold\n","\n","# Get true labels and predictions for validation set\n","y_true_val = []\n","y_pred_val = []\n","for X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n","    y_true_val += y_batch.numpy().tolist()\n","    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n","\n","# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n","# Competition Leaderboard Metric\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","\n","# Plot pF1 by threshold plot to find best threshold\n","pf1_by_threshold = []\n","thresholds = np.arange(0, 1.01, 0.01)\n","for t in tqdm(thresholds):\n","    # Compute pF1 for each threshold\n","    pf1_by_threshold.append(\n","        pfbeta(y_true_val, y_pred_val > t)\n","    )\n","    \n","plt.figure(figsize=(15,8))\n","plt.title('F1 By Threshold', size=24)\n","plt.plot(pf1_by_threshold, label='F1 Score')\n","\n","# Best threshold and pF1 score\n","arg_max = np.argmax(pf1_by_threshold)\n","val_max = np.max(pf1_by_threshold)\n","threshold_best = thresholds[arg_max]\n","plt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n","\n","# Plot pF1 by Threshold\n","plt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\n","plt.yticks(np.arange(0, 1.1, 0.1))\n","plt.xlim(0, 100)\n","plt.ylim(0, 1)\n","plt.xlabel('Threshold')\n","plt.ylabel('pF1 Score')\n","plt.legend(fontsize=12)\n","plt.grid()\n","plt.show()\n","print(f'Best Threshold {threshold_best:.2f}.')\n","\n","print(f'pF1 Score: {val_max:.2f}.')\n","\n","# Training History"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python convext_m1.py"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z"},"trusted":true},"outputs":[],"source":["%%writefile convext_m2.py\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from tqdm.notebook import tqdm\n","from multiprocessing import cpu_count\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import train_test_split\n","from keras_cv_attention_models import convnext\n","\n","import os\n","import time\n","import pickle\n","import math\n","import random\n","import sys\n","import cv2\n","import gc\n","import datetime\n","\n","print(f'Tensorflow Version: {tf.__version__}')\n","print(f'Python Version: {sys.version}')\n","\n","# Save Versions\n","\n","now = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n","np.save(now, np.array([now]))\n","\n","# Mixed Precision Policy\n","\n","# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n","# TPU is fast enough and has enough memory to use float32\n","policy = tf.keras.mixed_precision.Policy('float32')\n","tf.keras.mixed_precision.set_global_policy(policy)\n","\n","print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","\n","# Matplotlib Config\n","\n","# MatplotLib Global Settings\n","mpl.rcParams.update(mpl.rcParamsDefault)\n","mpl.rcParams['xtick.labelsize'] = 16\n","mpl.rcParams['ytick.labelsize'] = 16\n","mpl.rcParams['axes.labelsize'] = 18\n","mpl.rcParams['axes.titlesize'] = 24\n","\n","# Config\n","\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","    print('Running on TPU ', TPU.master())\n","except ValueError:\n","    print('Running on GPU')\n","    TPU = None\n","\n","if TPU:\n","    IS_TPU = True\n","    tf.config.experimental_connect_to_cluster(TPU)\n","    tf.tpu.experimental.initialize_tpu_system(TPU)\n","    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n","else:\n","    IS_TPU = False\n","    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","N_REPLICAS = STRATEGY.num_replicas_in_sync\n","print(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n","\n","#/kaggle/input/rsna-tfrecords-768x1344-dataset\n","\n","# For TPU's the dataset needs to be stored in Google Cloud\n","# Retrieve the Google Cloud location of the dataset\n","GCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n","\n","SEED = 43\n","DEBUG = False\n","VERSION = 'convext_m2'\n","# Image dimensions\n","IMG_HEIGHT = 1344\n","IMG_WIDTH = 768\n","N_CHANNELS = 1\n","INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\n","N_SAMPLES_TFRECORDS = 548\n","\n","# Peak Learning Rate\n","LR_MAX = 5e-6 * N_REPLICAS\n","WD_RATIO = 0.008\n","\n","N_WARMUP_EPOCHS = 0\n","N_EPOCHS = 10\n","\n","# Batch size\n","BATCH_SIZE = 8 * N_REPLICAS\n","\n","# Is Interactive Flag and COrresponding Verbosity Method\n","IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","VERBOSE = 1 if IS_INTERACTIVE else 2\n","\n","# Tensorflow AUTO flag\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","print(f'BATCH_SIZE: {BATCH_SIZE}')\n","\n","# Seed\n","\n","# Seed all random number generators\n","def seed_everything(seed=SEED):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything()\n","\n","# Train\n","\n","# Train DataFrame\n","train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n","\n","\n","# Utility Functions\n","\n","# short Tensorflow randin integer function\n","def tf_rand_int(minval, maxval, dtype=tf.int64):\n","    minval = tf.cast(minval, dtype)\n","    maxval = tf.cast(maxval, dtype)\n","    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n","\n","# chance of 1 in k\n","def one_in(k):\n","    return 0 == tf_rand_int(0, k)\n","\n","# Dataset\n","\n","# Function to benchmark the dataset\n","def benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n","    start_time = time.perf_counter()\n","    for epoch_num in range(num_epochs):\n","        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n","            if idx == 0:\n","                epoch_start = time.perf_counter()\n","            elif idx == 1 and epoch_num == 0:\n","                image = inputs['image']\n","                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n","            else:\n","                pass\n","        \n","        epoch_t = time.perf_counter() - epoch_start\n","        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n","        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n","        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n","\n","# Plots a batch of images\n","def show_batch(dataset, n_rows=16, n_cols=4):\n","    inputs, targets = next(iter(dataset))\n","    images = inputs['image'].numpy().squeeze()\n","    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            idx = r * n_cols + c\n","            # Image\n","            img = images[idx]\n","            axes[r, c].imshow(img)\n","            # Target\n","            target = targets[idx]\n","            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n","        \n","    plt.show()\n","\n","# Decodes the TFRecords\n","def decode_image(record_bytes):\n","    features = tf.io.parse_single_example(record_bytes, {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'target': tf.io.FixedLenFeature([], tf.int64),\n","        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n","    })\n","    \n","    # Decode PNG Image\n","    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n","    # Explicit reshape needed for TPU\n","    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n","\n","    target = features['target']\n","    \n","    return { 'image': image }, target\n","\n","def augment_image(X, y):\n","    image = X['image']\n","    \n","    # Random Brightness\n","    image = tf.image.random_brightness(image, 0.10)\n","    \n","    # Random Contrast\n","    image = tf.image.random_contrast(image, 0.90, 1.10)\n","    \n","    # Random JPEG Quality\n","    image = tf.image.random_jpeg_quality(image, 75, 100)\n","    \n","    # Random crop image with maximum of 10%\n","    ratio = tf.random.uniform([], 0.75, 1.00)\n","    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n","    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n","    # Random offset for crop\n","    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n","    img_width_offset = 0\n","    # Crop And Resize\n","    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n","    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n","    # Clip pixel values in range [0,255] to prevent underflow/overflow\n","    image = tf.clip_by_value(image, 0, 255)\n","    image = tf.cast(image, tf.uint8)\n","    \n","    return { 'image': image }, y\n","\n","# Undersample majority class (0/negative) by randomly dropping them\n","def undersample_majority(X, y):\n","    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n","    return y == 1 or tf.random.uniform([]) > 0.76\n","\n","# TFRecord file paths\n","TFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\n","print(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n","\n","# Train Test Split\n","TFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","TFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\n","TFRECORDS_TRAIN3, TFRECORDS_VAL3 = train_test_split(TFRECORDS_TRAIN2, train_size=0.67, random_state=SEED, shuffle=True)\n","\n","TFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL3]\n","TFRECORDS_VAL = TFRECORDS_VAL3\n","print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","def get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False\n","    \n","    # Initialize dataset with TFRecords\n","    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n","    \n","    # Decode mapping\n","    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n","\n","    if not val:\n","        dataset = dataset.filter(undersample_majority)\n","        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n","        dataset = dataset.with_options(ignore_order)\n","        if not debug:\n","            dataset = dataset.shuffle(1024)\n","        dataset = dataset.repeat()        \n","\n","    dataset = dataset.batch(bs, drop_remainder=not val)\n","    dataset = dataset.prefetch(AUTO)\n","    \n","    return dataset\n","\n","# Get Train/Validation datasets\n","train_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\n","val_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n","\n","TRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","VAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","print(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n","\n","# Sanity check, image and label statistics\n","X_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\n","image = X_batch['image'].numpy()\n","print(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\n","print(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\n","print(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n","\n","# Benchmark Dataset\n","benchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n","\n","# Show what we will be training on\n","show_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n","\n","# Tensorflow custom metric is just a conventional class object\n","class pF1(tf.keras.metrics.Metric):\n","    # Initialize properties\n","    def __init__(self, name='pF1', **kwargs):\n","        super(pF1, self).__init__(name=name, **kwargs)\n","        self.tc = self.add_weight(name='tc', initializer='zeros')\n","        self.tp = self.add_weight(name='tp', initializer='zeros')\n","        self.fp = self.add_weight(name='fp', initializer='zeros')\n","\n","    # Update state called on each batch with true and predicted labels\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n","        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n","        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n","\n","    # Result function is called to obtain result which is printed in progress bar\n","    def result(self):\n","        if self.tc == 0 or (self.tp + self.fp) == 0:\n","            return 0.0\n","        else:\n","            precision = self.tp / (self.tp + self.fp)\n","            recall = self.tp / (self.tc)\n","            return 2 * (precision * recall) / (precision + recall)\n","\n","    # Reset state is called after each epoch to start fresh each epoch\n","    def reset_state(self):\n","        self.tc.assign(0)\n","        self.tp.assign(0)\n","        self.fp.assign(0)\n","\n","def normalize(image):\n","    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n","    image = tf.repeat(image, repeats=3, axis=3)\n","    # Cast to float 32\n","    image = tf.cast(image, tf.float32)\n","    # Normalize with respect to ImageNet mean/std\n","    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n","\n","    return image\n","\n","def get_model():\n","    # Verify Mixed Policy Settings\n","    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","    \n","    with STRATEGY.scope():\n","        # Set seed for deterministic weights initialization\n","        seed_everything()\n","        \n","        # Inputs, note the names are equal to the dictionary keys in the dataset\n","        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n","        \n","        # Normalize Input\n","        image_norm = normalize(image)\n","\n","        # CNN Prediction in range [0,1]\n","        x = convnext.ConvNeXtV2Tiny(\n","            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n","            pretrained='imagenet21k-ft1k',\n","            num_classes=0,\n","        )(image_norm)\n","        \n","        # Average Pooling BxHxWxC -> BxC\n","        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","        # Dropout to prevent Overfitting\n","        x = tf.keras.layers.Dropout(0.30)(x)\n","        # Output value between [0, 1] using Sigmoid function\n","        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","        # We will use the famous AdamW optimizer for fast learning with weight decay\n","        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n","\n","        # Loss\n","        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n","        \n","        # Metrics\n","        metrics = [\n","            pF1(),\n","            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n","            tf.keras.metrics.Precision(),\n","            tf.keras.metrics.Recall(),\n","            tf.keras.metrics.AUC(),\n","            tf.keras.metrics.BinaryAccuracy(),\n","        ]\n","\n","        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n","        \n","        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","        return model\n","\n","# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\n","tf.keras.backend.clear_session()\n","# enable XLA optmizations\n","tf.config.optimizer.set_jit(True)\n","\n","model = get_model()\n","\n","# Weight Initilization\n","\n","# Validation metric on initialized model\n","_ = model.evaluate(\n","        get_dataset(TFRECORDS_VAL, val=True),\n","        verbose=VERBOSE,\n","        steps=VAL_STEPS_PER_EPOCH,\n","    )\n","\n","# Learning rate scheduler with logaritmic warmup and cosine decay\n","def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n","    \n","    if current_step < num_warmup_steps:\n","        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n","    else:\n","        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n","\n","        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n","\n","# Plot the learning rate scheduler\n","def plot_lr_schedule(lr_schedule, epochs):\n","    fig = plt.figure(figsize=(20, 10))\n","    plt.plot([None] + lr_schedule + [None])\n","    # X Labels\n","    x = np.arange(1, epochs + 1)\n","    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n","    plt.xlim([1, epochs])\n","    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n","    \n","    # Increase y-limit for better readability\n","    plt.ylim([0, max(lr_schedule) * 1.1])\n","    \n","    # Title\n","    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n","    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n","    \n","    # Plot Learning Rates\n","    for x, val in enumerate(lr_schedule):\n","        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n","            if x < len(lr_schedule) - 1:\n","                if lr_schedule[x - 1] < val:\n","                    ha = 'right'\n","                else:\n","                    ha = 'left'\n","            elif x == 0:\n","                ha = 'right'\n","            else:\n","                ha = 'left'\n","            plt.plot(x + 1, val, 'o', color='black');\n","            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n","            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n","    \n","    plt.xlabel('Epoch', size=16, labelpad=5)\n","    plt.ylabel('Learning Rate', size=16, labelpad=5)\n","    plt.grid()\n","    plt.show()\n","\n","# Learning rate for encoder\n","LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n","plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n","\n","# Learning Rate Callback\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n","\n","# Weight Decay Callback\n","\n","# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\n","class WeightDecayCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, wd_ratio=WD_RATIO):\n","        self.step_counter = 0\n","        self.wd_ratio = wd_ratio\n","    \n","    def on_epoch_begin(self, epoch, logs=None):\n","        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n","        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n","\n","# Train model on TPU!\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=f'best_{VERSION}.h5',\n","    save_weights_only=True,\n","    monitor='val_pF1',\n","    mode='max',\n","    save_best_only=True)\n","history = model.fit(\n","        train_dataset,\n","        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n","        validation_data = val_dataset,\n","        epochs = N_EPOCHS,\n","        verbose = VERBOSE,\n","        callbacks = [\n","            model_checkpoint_callback,\n","            lr_callback,\n","            WeightDecayCallback(),\n","        ],\n","        class_weight = {\n","            0: 1.0,\n","            1: 5.0,\n","        },\n","    )\n","\n","# Save model weights for inference\n","model.save_weights(f'model_{VERSION}.h5')\n","\n","# F1 By Threshold\n","\n","# Get true labels and predictions for validation set\n","y_true_val = []\n","y_pred_val = []\n","for X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n","    y_true_val += y_batch.numpy().tolist()\n","    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n","\n","# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n","# Competition Leaderboard Metric\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","\n","# Plot pF1 by threshold plot to find best threshold\n","pf1_by_threshold = []\n","thresholds = np.arange(0, 1.01, 0.01)\n","for t in tqdm(thresholds):\n","    # Compute pF1 for each threshold\n","    pf1_by_threshold.append(\n","        pfbeta(y_true_val, y_pred_val > t)\n","    )\n","    \n","plt.figure(figsize=(15,8))\n","plt.title('F1 By Threshold', size=24)\n","plt.plot(pf1_by_threshold, label='F1 Score')\n","\n","# Best threshold and pF1 score\n","arg_max = np.argmax(pf1_by_threshold)\n","val_max = np.max(pf1_by_threshold)\n","threshold_best = thresholds[arg_max]\n","plt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n","\n","# Plot pF1 by Threshold\n","plt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\n","plt.yticks(np.arange(0, 1.1, 0.1))\n","plt.xlim(0, 100)\n","plt.ylim(0, 1)\n","plt.xlabel('Threshold')\n","plt.ylabel('pF1 Score')\n","plt.legend(fontsize=12)\n","plt.grid()\n","plt.show()\n","print(f'Best Threshold {threshold_best:.2f}.')\n","\n","print(f'pF1 Score: {val_max:.2f}.')\n","\n","# Training History"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python convext_m2.py"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z"},"trusted":true},"outputs":[],"source":["%%writefile convext_m3.py\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from tqdm.notebook import tqdm\n","from multiprocessing import cpu_count\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import train_test_split\n","from keras_cv_attention_models import convnext\n","\n","import os\n","import time\n","import pickle\n","import math\n","import random\n","import sys\n","import cv2\n","import gc\n","import datetime\n","\n","print(f'Tensorflow Version: {tf.__version__}')\n","print(f'Python Version: {sys.version}')\n","\n","# Save Versions\n","\n","now = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n","np.save(now, np.array([now]))\n","\n","# Mixed Precision Policy\n","\n","# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n","# TPU is fast enough and has enough memory to use float32\n","policy = tf.keras.mixed_precision.Policy('float32')\n","tf.keras.mixed_precision.set_global_policy(policy)\n","\n","print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","\n","# Matplotlib Config\n","\n","# MatplotLib Global Settings\n","mpl.rcParams.update(mpl.rcParamsDefault)\n","mpl.rcParams['xtick.labelsize'] = 16\n","mpl.rcParams['ytick.labelsize'] = 16\n","mpl.rcParams['axes.labelsize'] = 18\n","mpl.rcParams['axes.titlesize'] = 24\n","\n","# Config\n","\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","    print('Running on TPU ', TPU.master())\n","except ValueError:\n","    print('Running on GPU')\n","    TPU = None\n","\n","if TPU:\n","    IS_TPU = True\n","    tf.config.experimental_connect_to_cluster(TPU)\n","    tf.tpu.experimental.initialize_tpu_system(TPU)\n","    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n","else:\n","    IS_TPU = False\n","    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","N_REPLICAS = STRATEGY.num_replicas_in_sync\n","print(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n","\n","#/kaggle/input/rsna-tfrecords-768x1344-dataset\n","\n","# For TPU's the dataset needs to be stored in Google Cloud\n","# Retrieve the Google Cloud location of the dataset\n","GCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n","\n","SEED = 43\n","DEBUG = False\n","VERSION = 'convext_m3'\n","# Image dimensions\n","IMG_HEIGHT = 1344\n","IMG_WIDTH = 768\n","N_CHANNELS = 1\n","INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\n","N_SAMPLES_TFRECORDS = 548\n","\n","# Peak Learning Rate\n","LR_MAX = 5e-6 * N_REPLICAS\n","WD_RATIO = 0.008\n","\n","N_WARMUP_EPOCHS = 0\n","N_EPOCHS = 10\n","\n","# Batch size\n","BATCH_SIZE = 8 * N_REPLICAS\n","\n","# Is Interactive Flag and COrresponding Verbosity Method\n","IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","VERBOSE = 1 if IS_INTERACTIVE else 2\n","\n","# Tensorflow AUTO flag\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","print(f'BATCH_SIZE: {BATCH_SIZE}')\n","\n","# Seed\n","\n","# Seed all random number generators\n","def seed_everything(seed=SEED):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything()\n","\n","# Train\n","\n","# Train DataFrame\n","train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n","\n","\n","# Utility Functions\n","\n","# short Tensorflow randin integer function\n","def tf_rand_int(minval, maxval, dtype=tf.int64):\n","    minval = tf.cast(minval, dtype)\n","    maxval = tf.cast(maxval, dtype)\n","    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n","\n","# chance of 1 in k\n","def one_in(k):\n","    return 0 == tf_rand_int(0, k)\n","\n","# Dataset\n","\n","# Function to benchmark the dataset\n","def benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n","    start_time = time.perf_counter()\n","    for epoch_num in range(num_epochs):\n","        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n","            if idx == 0:\n","                epoch_start = time.perf_counter()\n","            elif idx == 1 and epoch_num == 0:\n","                image = inputs['image']\n","                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n","            else:\n","                pass\n","        \n","        epoch_t = time.perf_counter() - epoch_start\n","        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n","        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n","        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n","\n","# Plots a batch of images\n","def show_batch(dataset, n_rows=16, n_cols=4):\n","    inputs, targets = next(iter(dataset))\n","    images = inputs['image'].numpy().squeeze()\n","    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            idx = r * n_cols + c\n","            # Image\n","            img = images[idx]\n","            axes[r, c].imshow(img)\n","            # Target\n","            target = targets[idx]\n","            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n","        \n","    plt.show()\n","\n","# Decodes the TFRecords\n","def decode_image(record_bytes):\n","    features = tf.io.parse_single_example(record_bytes, {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'target': tf.io.FixedLenFeature([], tf.int64),\n","        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n","    })\n","    \n","    # Decode PNG Image\n","    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n","    # Explicit reshape needed for TPU\n","    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n","\n","    target = features['target']\n","    \n","    return { 'image': image }, target\n","\n","def augment_image(X, y):\n","    image = X['image']\n","    \n","    # Random Brightness\n","    image = tf.image.random_brightness(image, 0.10)\n","    \n","    # Random Contrast\n","    image = tf.image.random_contrast(image, 0.90, 1.10)\n","    \n","    # Random JPEG Quality\n","    image = tf.image.random_jpeg_quality(image, 75, 100)\n","    \n","    # Random crop image with maximum of 10%\n","    ratio = tf.random.uniform([], 0.75, 1.00)\n","    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n","    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n","    # Random offset for crop\n","    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n","    img_width_offset = 0\n","    # Crop And Resize\n","    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n","    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n","    # Clip pixel values in range [0,255] to prevent underflow/overflow\n","    image = tf.clip_by_value(image, 0, 255)\n","    image = tf.cast(image, tf.uint8)\n","    \n","    return { 'image': image }, y\n","\n","# Undersample majority class (0/negative) by randomly dropping them\n","def undersample_majority(X, y):\n","    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n","    return y == 1 or tf.random.uniform([]) > 0.76\n","\n","# TFRecord file paths\n","TFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\n","print(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n","\n","# Train Test Split\n","TFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","TFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\n","TFRECORDS_TRAIN3, TFRECORDS_VAL3 = train_test_split(TFRECORDS_TRAIN2, train_size=0.67, random_state=SEED, shuffle=True)\n","TFRECORDS_TRAIN4, TFRECORDS_VAL4 = train_test_split(TFRECORDS_TRAIN3, train_size=0.5, random_state=SEED, shuffle=True)\n","\n","TFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL4]\n","TFRECORDS_VAL = TFRECORDS_VAL4\n","print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","def get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False\n","    \n","    # Initialize dataset with TFRecords\n","    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n","    \n","    # Decode mapping\n","    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n","\n","    if not val:\n","        dataset = dataset.filter(undersample_majority)\n","        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n","        dataset = dataset.with_options(ignore_order)\n","        if not debug:\n","            dataset = dataset.shuffle(1024)\n","        dataset = dataset.repeat()        \n","\n","    dataset = dataset.batch(bs, drop_remainder=not val)\n","    dataset = dataset.prefetch(AUTO)\n","    \n","    return dataset\n","\n","# Get Train/Validation datasets\n","train_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\n","val_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n","\n","TRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","VAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","print(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n","\n","# Sanity check, image and label statistics\n","X_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\n","image = X_batch['image'].numpy()\n","print(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\n","print(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\n","print(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n","\n","# Benchmark Dataset\n","benchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n","\n","# Show what we will be training on\n","show_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n","\n","# Tensorflow custom metric is just a conventional class object\n","class pF1(tf.keras.metrics.Metric):\n","    # Initialize properties\n","    def __init__(self, name='pF1', **kwargs):\n","        super(pF1, self).__init__(name=name, **kwargs)\n","        self.tc = self.add_weight(name='tc', initializer='zeros')\n","        self.tp = self.add_weight(name='tp', initializer='zeros')\n","        self.fp = self.add_weight(name='fp', initializer='zeros')\n","\n","    # Update state called on each batch with true and predicted labels\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n","        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n","        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n","\n","    # Result function is called to obtain result which is printed in progress bar\n","    def result(self):\n","        if self.tc == 0 or (self.tp + self.fp) == 0:\n","            return 0.0\n","        else:\n","            precision = self.tp / (self.tp + self.fp)\n","            recall = self.tp / (self.tc)\n","            return 2 * (precision * recall) / (precision + recall)\n","\n","    # Reset state is called after each epoch to start fresh each epoch\n","    def reset_state(self):\n","        self.tc.assign(0)\n","        self.tp.assign(0)\n","        self.fp.assign(0)\n","\n","def normalize(image):\n","    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n","    image = tf.repeat(image, repeats=3, axis=3)\n","    # Cast to float 32\n","    image = tf.cast(image, tf.float32)\n","    # Normalize with respect to ImageNet mean/std\n","    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n","\n","    return image\n","\n","def get_model():\n","    # Verify Mixed Policy Settings\n","    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","    \n","    with STRATEGY.scope():\n","        # Set seed for deterministic weights initialization\n","        seed_everything()\n","        \n","        # Inputs, note the names are equal to the dictionary keys in the dataset\n","        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n","        \n","        # Normalize Input\n","        image_norm = normalize(image)\n","\n","        # CNN Prediction in range [0,1]\n","        x = convnext.ConvNeXtV2Tiny(\n","            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n","            pretrained='imagenet21k-ft1k',\n","            num_classes=0,\n","        )(image_norm)\n","        \n","        # Average Pooling BxHxWxC -> BxC\n","        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","        # Dropout to prevent Overfitting\n","        x = tf.keras.layers.Dropout(0.30)(x)\n","        # Output value between [0, 1] using Sigmoid function\n","        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","        # We will use the famous AdamW optimizer for fast learning with weight decay\n","        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n","\n","        # Loss\n","        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n","        \n","        # Metrics\n","        metrics = [\n","            pF1(),\n","            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n","            tf.keras.metrics.Precision(),\n","            tf.keras.metrics.Recall(),\n","            tf.keras.metrics.AUC(),\n","            tf.keras.metrics.BinaryAccuracy(),\n","        ]\n","\n","        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n","        \n","        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","        return model\n","\n","# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\n","tf.keras.backend.clear_session()\n","# enable XLA optmizations\n","tf.config.optimizer.set_jit(True)\n","\n","model = get_model()\n","\n","# Weight Initilization\n","\n","# Validation metric on initialized model\n","_ = model.evaluate(\n","        get_dataset(TFRECORDS_VAL, val=True),\n","        verbose=VERBOSE,\n","        steps=VAL_STEPS_PER_EPOCH,\n","    )\n","\n","# Learning rate scheduler with logaritmic warmup and cosine decay\n","def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n","    \n","    if current_step < num_warmup_steps:\n","        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n","    else:\n","        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n","\n","        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n","\n","# Plot the learning rate scheduler\n","def plot_lr_schedule(lr_schedule, epochs):\n","    fig = plt.figure(figsize=(20, 10))\n","    plt.plot([None] + lr_schedule + [None])\n","    # X Labels\n","    x = np.arange(1, epochs + 1)\n","    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n","    plt.xlim([1, epochs])\n","    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n","    \n","    # Increase y-limit for better readability\n","    plt.ylim([0, max(lr_schedule) * 1.1])\n","    \n","    # Title\n","    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n","    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n","    \n","    # Plot Learning Rates\n","    for x, val in enumerate(lr_schedule):\n","        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n","            if x < len(lr_schedule) - 1:\n","                if lr_schedule[x - 1] < val:\n","                    ha = 'right'\n","                else:\n","                    ha = 'left'\n","            elif x == 0:\n","                ha = 'right'\n","            else:\n","                ha = 'left'\n","            plt.plot(x + 1, val, 'o', color='black');\n","            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n","            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n","    \n","    plt.xlabel('Epoch', size=16, labelpad=5)\n","    plt.ylabel('Learning Rate', size=16, labelpad=5)\n","    plt.grid()\n","    plt.show()\n","\n","# Learning rate for encoder\n","LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n","plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n","\n","# Learning Rate Callback\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n","\n","# Weight Decay Callback\n","\n","# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\n","class WeightDecayCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, wd_ratio=WD_RATIO):\n","        self.step_counter = 0\n","        self.wd_ratio = wd_ratio\n","    \n","    def on_epoch_begin(self, epoch, logs=None):\n","        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n","        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n","\n","# Train model on TPU!\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=f'best_{VERSION}.h5',\n","    save_weights_only=True,\n","    monitor='val_pF1',\n","    mode='max',\n","    save_best_only=True)\n","history = model.fit(\n","        train_dataset,\n","        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n","        validation_data = val_dataset,\n","        epochs = N_EPOCHS,\n","        verbose = VERBOSE,\n","        callbacks = [\n","            model_checkpoint_callback,\n","            lr_callback,\n","            WeightDecayCallback(),\n","        ],\n","        class_weight = {\n","            0: 1.0,\n","            1: 5.0,\n","        },\n","    )\n","\n","# Save model weights for inference\n","model.save_weights(f'model_{VERSION}.h5')\n","\n","# F1 By Threshold\n","\n","# Get true labels and predictions for validation set\n","y_true_val = []\n","y_pred_val = []\n","for X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n","    y_true_val += y_batch.numpy().tolist()\n","    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n","\n","# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n","# Competition Leaderboard Metric\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","\n","# Plot pF1 by threshold plot to find best threshold\n","pf1_by_threshold = []\n","thresholds = np.arange(0, 1.01, 0.01)\n","for t in tqdm(thresholds):\n","    # Compute pF1 for each threshold\n","    pf1_by_threshold.append(\n","        pfbeta(y_true_val, y_pred_val > t)\n","    )\n","    \n","plt.figure(figsize=(15,8))\n","plt.title('F1 By Threshold', size=24)\n","plt.plot(pf1_by_threshold, label='F1 Score')\n","\n","# Best threshold and pF1 score\n","arg_max = np.argmax(pf1_by_threshold)\n","val_max = np.max(pf1_by_threshold)\n","threshold_best = thresholds[arg_max]\n","plt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n","\n","# Plot pF1 by Threshold\n","plt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\n","plt.yticks(np.arange(0, 1.1, 0.1))\n","plt.xlim(0, 100)\n","plt.ylim(0, 1)\n","plt.xlabel('Threshold')\n","plt.ylabel('pF1 Score')\n","plt.legend(fontsize=12)\n","plt.grid()\n","plt.show()\n","print(f'Best Threshold {threshold_best:.2f}.')\n","\n","print(f'pF1 Score: {val_max:.2f}.')\n","\n","# Training History"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python convext_m3.py"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z"},"trusted":true},"outputs":[],"source":["%%writefile convext_m4.py\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from tqdm.notebook import tqdm\n","from multiprocessing import cpu_count\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import train_test_split\n","from keras_cv_attention_models import convnext\n","\n","import os\n","import time\n","import pickle\n","import math\n","import random\n","import sys\n","import cv2\n","import gc\n","import datetime\n","\n","print(f'Tensorflow Version: {tf.__version__}')\n","print(f'Python Version: {sys.version}')\n","\n","# Save Versions\n","\n","now = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n","np.save(now, np.array([now]))\n","\n","# Mixed Precision Policy\n","\n","# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n","# TPU is fast enough and has enough memory to use float32\n","policy = tf.keras.mixed_precision.Policy('float32')\n","tf.keras.mixed_precision.set_global_policy(policy)\n","\n","print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","\n","# Matplotlib Config\n","\n","# MatplotLib Global Settings\n","mpl.rcParams.update(mpl.rcParamsDefault)\n","mpl.rcParams['xtick.labelsize'] = 16\n","mpl.rcParams['ytick.labelsize'] = 16\n","mpl.rcParams['axes.labelsize'] = 18\n","mpl.rcParams['axes.titlesize'] = 24\n","\n","# Config\n","\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","    print('Running on TPU ', TPU.master())\n","except ValueError:\n","    print('Running on GPU')\n","    TPU = None\n","\n","if TPU:\n","    IS_TPU = True\n","    tf.config.experimental_connect_to_cluster(TPU)\n","    tf.tpu.experimental.initialize_tpu_system(TPU)\n","    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n","else:\n","    IS_TPU = False\n","    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","N_REPLICAS = STRATEGY.num_replicas_in_sync\n","print(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n","\n","#/kaggle/input/rsna-tfrecords-768x1344-dataset\n","\n","# For TPU's the dataset needs to be stored in Google Cloud\n","# Retrieve the Google Cloud location of the dataset\n","GCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n","\n","SEED = 43\n","DEBUG = False\n","VERSION = 'convext_m4'\n","# Image dimensions\n","IMG_HEIGHT = 1344\n","IMG_WIDTH = 768\n","N_CHANNELS = 1\n","INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\n","N_SAMPLES_TFRECORDS = 548\n","\n","# Peak Learning Rate\n","LR_MAX = 5e-6 * N_REPLICAS\n","WD_RATIO = 0.008\n","\n","N_WARMUP_EPOCHS = 0\n","N_EPOCHS = 10\n","\n","# Batch size\n","BATCH_SIZE = 8 * N_REPLICAS\n","\n","# Is Interactive Flag and COrresponding Verbosity Method\n","IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","VERBOSE = 1 if IS_INTERACTIVE else 2\n","\n","# Tensorflow AUTO flag\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","print(f'BATCH_SIZE: {BATCH_SIZE}')\n","\n","# Seed\n","\n","# Seed all random number generators\n","def seed_everything(seed=SEED):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything()\n","\n","# Train\n","\n","# Train DataFrame\n","train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n","\n","\n","# Utility Functions\n","\n","# short Tensorflow randin integer function\n","def tf_rand_int(minval, maxval, dtype=tf.int64):\n","    minval = tf.cast(minval, dtype)\n","    maxval = tf.cast(maxval, dtype)\n","    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n","\n","# chance of 1 in k\n","def one_in(k):\n","    return 0 == tf_rand_int(0, k)\n","\n","# Dataset\n","\n","# Function to benchmark the dataset\n","def benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n","    start_time = time.perf_counter()\n","    for epoch_num in range(num_epochs):\n","        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n","            if idx == 0:\n","                epoch_start = time.perf_counter()\n","            elif idx == 1 and epoch_num == 0:\n","                image = inputs['image']\n","                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n","            else:\n","                pass\n","        \n","        epoch_t = time.perf_counter() - epoch_start\n","        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n","        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n","        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n","\n","# Plots a batch of images\n","def show_batch(dataset, n_rows=16, n_cols=4):\n","    inputs, targets = next(iter(dataset))\n","    images = inputs['image'].numpy().squeeze()\n","    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            idx = r * n_cols + c\n","            # Image\n","            img = images[idx]\n","            axes[r, c].imshow(img)\n","            # Target\n","            target = targets[idx]\n","            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n","        \n","    plt.show()\n","\n","# Decodes the TFRecords\n","def decode_image(record_bytes):\n","    features = tf.io.parse_single_example(record_bytes, {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'target': tf.io.FixedLenFeature([], tf.int64),\n","        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n","    })\n","    \n","    # Decode PNG Image\n","    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n","    # Explicit reshape needed for TPU\n","    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n","\n","    target = features['target']\n","    \n","    return { 'image': image }, target\n","\n","def augment_image(X, y):\n","    image = X['image']\n","    \n","    # Random Brightness\n","    image = tf.image.random_brightness(image, 0.10)\n","    \n","    # Random Contrast\n","    image = tf.image.random_contrast(image, 0.90, 1.10)\n","    \n","    # Random JPEG Quality\n","    image = tf.image.random_jpeg_quality(image, 75, 100)\n","    \n","    # Random crop image with maximum of 10%\n","    ratio = tf.random.uniform([], 0.75, 1.00)\n","    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n","    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n","    # Random offset for crop\n","    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n","    img_width_offset = 0\n","    # Crop And Resize\n","    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n","    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n","    # Clip pixel values in range [0,255] to prevent underflow/overflow\n","    image = tf.clip_by_value(image, 0, 255)\n","    image = tf.cast(image, tf.uint8)\n","    \n","    return { 'image': image }, y\n","\n","# Undersample majority class (0/negative) by randomly dropping them\n","def undersample_majority(X, y):\n","    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n","    return y == 1 or tf.random.uniform([]) > 0.76\n","\n","# TFRecord file paths\n","TFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\n","print(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n","\n","# Train Test Split\n","TFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","TFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n","#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\n","TFRECORDS_TRAIN3, TFRECORDS_VAL3 = train_test_split(TFRECORDS_TRAIN2, train_size=0.67, random_state=SEED, shuffle=True)\n","TFRECORDS_TRAIN4, TFRECORDS_VAL4 = train_test_split(TFRECORDS_TRAIN3, train_size=0.5, random_state=SEED, shuffle=True)\n","\n","TFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_TRAIN4]\n","TFRECORDS_VAL = TFRECORDS_TRAIN4\n","print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n","def get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False\n","    \n","    # Initialize dataset with TFRecords\n","    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n","    \n","    # Decode mapping\n","    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n","\n","    if not val:\n","        dataset = dataset.filter(undersample_majority)\n","        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n","        dataset = dataset.with_options(ignore_order)\n","        if not debug:\n","            dataset = dataset.shuffle(1024)\n","        dataset = dataset.repeat()        \n","\n","    dataset = dataset.batch(bs, drop_remainder=not val)\n","    dataset = dataset.prefetch(AUTO)\n","    \n","    return dataset\n","\n","# Get Train/Validation datasets\n","train_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\n","val_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n","\n","TRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","VAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n","print(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n","\n","# Sanity check, image and label statistics\n","X_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\n","image = X_batch['image'].numpy()\n","print(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\n","print(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\n","print(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n","\n","# Benchmark Dataset\n","benchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n","\n","# Show what we will be training on\n","show_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n","\n","# Tensorflow custom metric is just a conventional class object\n","class pF1(tf.keras.metrics.Metric):\n","    # Initialize properties\n","    def __init__(self, name='pF1', **kwargs):\n","        super(pF1, self).__init__(name=name, **kwargs)\n","        self.tc = self.add_weight(name='tc', initializer='zeros')\n","        self.tp = self.add_weight(name='tp', initializer='zeros')\n","        self.fp = self.add_weight(name='fp', initializer='zeros')\n","\n","    # Update state called on each batch with true and predicted labels\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n","        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n","        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n","\n","    # Result function is called to obtain result which is printed in progress bar\n","    def result(self):\n","        if self.tc == 0 or (self.tp + self.fp) == 0:\n","            return 0.0\n","        else:\n","            precision = self.tp / (self.tp + self.fp)\n","            recall = self.tp / (self.tc)\n","            return 2 * (precision * recall) / (precision + recall)\n","\n","    # Reset state is called after each epoch to start fresh each epoch\n","    def reset_state(self):\n","        self.tc.assign(0)\n","        self.tp.assign(0)\n","        self.fp.assign(0)\n","\n","def normalize(image):\n","    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n","    image = tf.repeat(image, repeats=3, axis=3)\n","    # Cast to float 32\n","    image = tf.cast(image, tf.float32)\n","    # Normalize with respect to ImageNet mean/std\n","    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n","\n","    return image\n","\n","def get_model():\n","    # Verify Mixed Policy Settings\n","    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","    \n","    with STRATEGY.scope():\n","        # Set seed for deterministic weights initialization\n","        seed_everything()\n","        \n","        # Inputs, note the names are equal to the dictionary keys in the dataset\n","        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n","        \n","        # Normalize Input\n","        image_norm = normalize(image)\n","\n","        # CNN Prediction in range [0,1]\n","        x = convnext.ConvNeXtV2Tiny(\n","            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n","            pretrained='imagenet21k-ft1k',\n","            num_classes=0,\n","        )(image_norm)\n","        \n","        # Average Pooling BxHxWxC -> BxC\n","        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","        # Dropout to prevent Overfitting\n","        x = tf.keras.layers.Dropout(0.30)(x)\n","        # Output value between [0, 1] using Sigmoid function\n","        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","        # We will use the famous AdamW optimizer for fast learning with weight decay\n","        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n","\n","        # Loss\n","        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n","        \n","        # Metrics\n","        metrics = [\n","            pF1(),\n","            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n","            tf.keras.metrics.Precision(),\n","            tf.keras.metrics.Recall(),\n","            tf.keras.metrics.AUC(),\n","            tf.keras.metrics.BinaryAccuracy(),\n","        ]\n","\n","        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n","        \n","        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","        return model\n","\n","# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\n","tf.keras.backend.clear_session()\n","# enable XLA optmizations\n","tf.config.optimizer.set_jit(True)\n","\n","model = get_model()\n","\n","# Weight Initilization\n","\n","# Validation metric on initialized model\n","_ = model.evaluate(\n","        get_dataset(TFRECORDS_VAL, val=True),\n","        verbose=VERBOSE,\n","        steps=VAL_STEPS_PER_EPOCH,\n","    )\n","\n","# Learning rate scheduler with logaritmic warmup and cosine decay\n","def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n","    \n","    if current_step < num_warmup_steps:\n","        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n","    else:\n","        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n","\n","        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n","\n","# Plot the learning rate scheduler\n","def plot_lr_schedule(lr_schedule, epochs):\n","    fig = plt.figure(figsize=(20, 10))\n","    plt.plot([None] + lr_schedule + [None])\n","    # X Labels\n","    x = np.arange(1, epochs + 1)\n","    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n","    plt.xlim([1, epochs])\n","    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n","    \n","    # Increase y-limit for better readability\n","    plt.ylim([0, max(lr_schedule) * 1.1])\n","    \n","    # Title\n","    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n","    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n","    \n","    # Plot Learning Rates\n","    for x, val in enumerate(lr_schedule):\n","        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n","            if x < len(lr_schedule) - 1:\n","                if lr_schedule[x - 1] < val:\n","                    ha = 'right'\n","                else:\n","                    ha = 'left'\n","            elif x == 0:\n","                ha = 'right'\n","            else:\n","                ha = 'left'\n","            plt.plot(x + 1, val, 'o', color='black');\n","            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n","            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n","    \n","    plt.xlabel('Epoch', size=16, labelpad=5)\n","    plt.ylabel('Learning Rate', size=16, labelpad=5)\n","    plt.grid()\n","    plt.show()\n","\n","# Learning rate for encoder\n","LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n","plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n","\n","# Learning Rate Callback\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n","\n","# Weight Decay Callback\n","\n","# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\n","class WeightDecayCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, wd_ratio=WD_RATIO):\n","        self.step_counter = 0\n","        self.wd_ratio = wd_ratio\n","    \n","    def on_epoch_begin(self, epoch, logs=None):\n","        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n","        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n","\n","# Train model on TPU!\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=f'best_{VERSION}.h5',\n","    save_weights_only=True,\n","    monitor='val_pF1',\n","    mode='max',\n","    save_best_only=True)\n","history = model.fit(\n","        train_dataset,\n","        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n","        validation_data = val_dataset,\n","        epochs = N_EPOCHS,\n","        verbose = VERBOSE,\n","        callbacks = [\n","            model_checkpoint_callback,\n","            lr_callback,\n","            WeightDecayCallback(),\n","        ],\n","        class_weight = {\n","            0: 1.0,\n","            1: 5.0,\n","        },\n","    )\n","\n","# Save model weights for inference\n","model.save_weights(f'model_{VERSION}.h5')\n","\n","# F1 By Threshold\n","\n","# Get true labels and predictions for validation set\n","y_true_val = []\n","y_pred_val = []\n","for X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n","    y_true_val += y_batch.numpy().tolist()\n","    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n","\n","# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n","# Competition Leaderboard Metric\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","\n","# Plot pF1 by threshold plot to find best threshold\n","pf1_by_threshold = []\n","thresholds = np.arange(0, 1.01, 0.01)\n","for t in tqdm(thresholds):\n","    # Compute pF1 for each threshold\n","    pf1_by_threshold.append(\n","        pfbeta(y_true_val, y_pred_val > t)\n","    )\n","    \n","plt.figure(figsize=(15,8))\n","plt.title('F1 By Threshold', size=24)\n","plt.plot(pf1_by_threshold, label='F1 Score')\n","\n","# Best threshold and pF1 score\n","arg_max = np.argmax(pf1_by_threshold)\n","val_max = np.max(pf1_by_threshold)\n","threshold_best = thresholds[arg_max]\n","plt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n","\n","# Plot pF1 by Threshold\n","plt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\n","plt.yticks(np.arange(0, 1.1, 0.1))\n","plt.xlim(0, 100)\n","plt.ylim(0, 1)\n","plt.xlabel('Threshold')\n","plt.ylabel('pF1 Score')\n","plt.legend(fontsize=12)\n","plt.grid()\n","plt.show()\n","print(f'Best Threshold {threshold_best:.2f}.')\n","\n","print(f'pF1 Score: {val_max:.2f}.')\n","\n","# Training History"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python convext_m4.py"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
