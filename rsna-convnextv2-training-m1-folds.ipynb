{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#https://www.kaggle.com/datasets/canming/rsna-tfrecords-768x1344-dataset2\n#https://www.kaggle.com/datasets/markwijkhuizen/keras-cv-attention-models\n#https://www.kaggle.com/competitions/rsna-breast-cancer-detection","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install ConvNextV2 Models From Keras CV Attention Models Pip Package\n!pip install -qq /kaggle/input/keras-cv-attention-models/keras_cv_attention_models-1.3.9-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:51:57.414272Z","iopub.execute_input":"2023-01-25T18:51:57.414576Z","iopub.status.idle":"2023-01-25T18:52:06.278282Z","shell.execute_reply.started":"2023-01-25T18:51:57.414501Z","shell.execute_reply":"2023-01-25T18:52:06.277519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile convext_m0.py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom keras_cv_attention_models import convnext\n\nimport os\nimport time\nimport pickle\nimport math\nimport random\nimport sys\nimport cv2\nimport gc\nimport datetime\n\nprint(f'Tensorflow Version: {tf.__version__}')\nprint(f'Python Version: {sys.version}')\n\n# Save Versions\n\nnow = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\nnp.save(now, np.array([now]))\n\n# Mixed Precision Policy\n\n# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n# TPU is fast enough and has enough memory to use float32\npolicy = tf.keras.mixed_precision.Policy('float32')\ntf.keras.mixed_precision.set_global_policy(policy)\n\nprint(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n\n# Matplotlib Config\n\n# MatplotLib Global Settings\nmpl.rcParams.update(mpl.rcParamsDefault)\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.labelsize'] = 18\nmpl.rcParams['axes.titlesize'] = 24\n\n# Config\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n\n#/kaggle/input/rsna-tfrecords-768x1344-dataset\n\n# For TPU's the dataset needs to be stored in Google Cloud\n# Retrieve the Google Cloud location of the dataset\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n\nSEED = 43\nDEBUG = False\nVERSION = 'convext_m0'\n# Image dimensions\nIMG_HEIGHT = 1344\nIMG_WIDTH = 768\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nLR_MAX = 5e-6 * N_REPLICAS\nWD_RATIO = 0.008\n\nN_WARMUP_EPOCHS = 0\nN_EPOCHS = 10\n\n# Batch size\nBATCH_SIZE = 8 * N_REPLICAS\n\n# Is Interactive Flag and COrresponding Verbosity Method\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')\n\n# Seed\n\n# Seed all random number generators\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()\n\n# Train\n\n# Train DataFrame\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n\n\n# Utility Functions\n\n# short Tensorflow randin integer function\ndef tf_rand_int(minval, maxval, dtype=tf.int64):\n    minval = tf.cast(minval, dtype)\n    maxval = tf.cast(maxval, dtype)\n    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n\n# chance of 1 in k\ndef one_in(k):\n    return 0 == tf_rand_int(0, k)\n\n# Dataset\n\n# Function to benchmark the dataset\ndef benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n            if idx == 0:\n                epoch_start = time.perf_counter()\n            elif idx == 1 and epoch_num == 0:\n                image = inputs['image']\n                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n            else:\n                pass\n        \n        epoch_t = time.perf_counter() - epoch_start\n        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n\n# Plots a batch of images\ndef show_batch(dataset, n_rows=16, n_cols=4):\n    inputs, targets = next(iter(dataset))\n    images = inputs['image'].numpy().squeeze()\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n    for r in range(n_rows):\n        for c in range(n_cols):\n            idx = r * n_cols + c\n            # Image\n            img = images[idx]\n            axes[r, c].imshow(img)\n            # Target\n            target = targets[idx]\n            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n        \n    plt.show()\n\n# Decodes the TFRecords\ndef decode_image(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n    })\n    \n    # Decode PNG Image\n    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n    # Explicit reshape needed for TPU\n    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n\n    target = features['target']\n    \n    return { 'image': image }, target\n\ndef augment_image(X, y):\n    image = X['image']\n    \n    # Random Brightness\n    image = tf.image.random_brightness(image, 0.10)\n    \n    # Random Contrast\n    image = tf.image.random_contrast(image, 0.90, 1.10)\n    \n    # Random JPEG Quality\n    image = tf.image.random_jpeg_quality(image, 75, 100)\n    \n    # Random crop image with maximum of 10%\n    ratio = tf.random.uniform([], 0.75, 1.00)\n    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n    # Random offset for crop\n    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n    img_width_offset = 0\n    # Crop And Resize\n    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n    # Clip pixel values in range [0,255] to prevent underflow/overflow\n    image = tf.clip_by_value(image, 0, 255)\n    image = tf.cast(image, tf.uint8)\n    \n    return { 'image': image }, y\n\n# Undersample majority class (0/negative) by randomly dropping them\ndef undersample_majority(X, y):\n    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n    return y == 1 or tf.random.uniform([]) > 0.76\n\n# TFRecord file paths\nTFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\nprint(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n\n# Train Test Split\nTFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\n#TFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\n#TFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL2]\n#TFRECORDS_VAL = TFRECORDS_VAL2\nprint(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\ndef get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    \n    # Initialize dataset with TFRecords\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n    \n    # Decode mapping\n    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n\n    if not val:\n        dataset = dataset.filter(undersample_majority)\n        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n        dataset = dataset.with_options(ignore_order)\n        if not debug:\n            dataset = dataset.shuffle(1024)\n        dataset = dataset.repeat()        \n\n    dataset = dataset.batch(bs, drop_remainder=not val)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset\n\n# Get Train/Validation datasets\ntrain_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\nval_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n\nTRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nVAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nprint(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n\n# Sanity check, image and label statistics\nX_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\nimage = X_batch['image'].numpy()\nprint(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\nprint(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\nprint(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n\n# Benchmark Dataset\nbenchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n\n# Show what we will be training on\nshow_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n\n# Tensorflow custom metric is just a conventional class object\nclass pF1(tf.keras.metrics.Metric):\n    # Initialize properties\n    def __init__(self, name='pF1', **kwargs):\n        super(pF1, self).__init__(name=name, **kwargs)\n        self.tc = self.add_weight(name='tc', initializer='zeros')\n        self.tp = self.add_weight(name='tp', initializer='zeros')\n        self.fp = self.add_weight(name='fp', initializer='zeros')\n\n    # Update state called on each batch with true and predicted labels\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n\n    # Result function is called to obtain result which is printed in progress bar\n    def result(self):\n        if self.tc == 0 or (self.tp + self.fp) == 0:\n            return 0.0\n        else:\n            precision = self.tp / (self.tp + self.fp)\n            recall = self.tp / (self.tc)\n            return 2 * (precision * recall) / (precision + recall)\n\n    # Reset state is called after each epoch to start fresh each epoch\n    def reset_state(self):\n        self.tc.assign(0)\n        self.tp.assign(0)\n        self.fp.assign(0)\n\ndef normalize(image):\n    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n    image = tf.repeat(image, repeats=3, axis=3)\n    # Cast to float 32\n    image = tf.cast(image, tf.float32)\n    # Normalize with respect to ImageNet mean/std\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image\n\ndef get_model():\n    # Verify Mixed Policy Settings\n    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n    \n    with STRATEGY.scope():\n        # Set seed for deterministic weights initialization\n        seed_everything()\n        \n        # Inputs, note the names are equal to the dictionary keys in the dataset\n        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n        \n        # Normalize Input\n        image_norm = normalize(image)\n\n        # CNN Prediction in range [0,1]\n        x = convnext.ConvNeXtV2Tiny(\n            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n            pretrained='imagenet21k-ft1k',\n            num_classes=0,\n        )(image_norm)\n        \n        # Average Pooling BxHxWxC -> BxC\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        # Dropout to prevent Overfitting\n        x = tf.keras.layers.Dropout(0.30)(x)\n        # Output value between [0, 1] using Sigmoid function\n        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n        # We will use the famous AdamW optimizer for fast learning with weight decay\n        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n\n        # Loss\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n        \n        # Metrics\n        metrics = [\n            pF1(),\n            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n            tf.keras.metrics.Precision(),\n            tf.keras.metrics.Recall(),\n            tf.keras.metrics.AUC(),\n            tf.keras.metrics.BinaryAccuracy(),\n        ]\n\n        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n        \n        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n        return model\n\n# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\ntf.keras.backend.clear_session()\n# enable XLA optmizations\ntf.config.optimizer.set_jit(True)\n\nmodel = get_model()\n\n# Weight Initilization\n\n# Validation metric on initialized model\n_ = model.evaluate(\n        get_dataset(TFRECORDS_VAL, val=True),\n        verbose=VERBOSE,\n        steps=VAL_STEPS_PER_EPOCH,\n    )\n\n# Learning rate scheduler with logaritmic warmup and cosine decay\ndef lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n    \n    if current_step < num_warmup_steps:\n        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n\n# Plot the learning rate scheduler\ndef plot_lr_schedule(lr_schedule, epochs):\n    fig = plt.figure(figsize=(20, 10))\n    plt.plot([None] + lr_schedule + [None])\n    # X Labels\n    x = np.arange(1, epochs + 1)\n    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n    plt.xlim([1, epochs])\n    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n    \n    # Increase y-limit for better readability\n    plt.ylim([0, max(lr_schedule) * 1.1])\n    \n    # Title\n    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n    \n    # Plot Learning Rates\n    for x, val in enumerate(lr_schedule):\n        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n            if x < len(lr_schedule) - 1:\n                if lr_schedule[x - 1] < val:\n                    ha = 'right'\n                else:\n                    ha = 'left'\n            elif x == 0:\n                ha = 'right'\n            else:\n                ha = 'left'\n            plt.plot(x + 1, val, 'o', color='black');\n            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n    \n    plt.xlabel('Epoch', size=16, labelpad=5)\n    plt.ylabel('Learning Rate', size=16, labelpad=5)\n    plt.grid()\n    plt.show()\n\n# Learning rate for encoder\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\nplot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n\n# Learning Rate Callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n\n# Weight Decay Callback\n\n# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\nclass WeightDecayCallback(tf.keras.callbacks.Callback):\n    def __init__(self, wd_ratio=WD_RATIO):\n        self.step_counter = 0\n        self.wd_ratio = wd_ratio\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n\n# Train model on TPU!\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=f'best_{VERSION}.h5',\n    save_weights_only=True,\n    monitor='val_pF1',\n    mode='max',\n    save_best_only=True)\nhistory = model.fit(\n        train_dataset,\n        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n        validation_data = val_dataset,\n        epochs = N_EPOCHS,\n        verbose = VERBOSE,\n        callbacks = [\n            model_checkpoint_callback,\n            lr_callback,\n            WeightDecayCallback(),\n        ],\n        class_weight = {\n            0: 1.0,\n            1: 5.0,\n        },\n    )\n\n# Save model weights for inference\nmodel.save_weights(f'model_{VERSION}.h5')\n\n# F1 By Threshold\n\n# Get true labels and predictions for validation set\ny_true_val = []\ny_pred_val = []\nfor X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n    y_true_val += y_batch.numpy().tolist()\n    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n\n# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n# Competition Leaderboard Metric\ndef pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0\n\n# Plot pF1 by threshold plot to find best threshold\npf1_by_threshold = []\nthresholds = np.arange(0, 1.01, 0.01)\nfor t in tqdm(thresholds):\n    # Compute pF1 for each threshold\n    pf1_by_threshold.append(\n        pfbeta(y_true_val, y_pred_val > t)\n    )\n    \nplt.figure(figsize=(15,8))\nplt.title('F1 By Threshold', size=24)\nplt.plot(pf1_by_threshold, label='F1 Score')\n\n# Best threshold and pF1 score\narg_max = np.argmax(pf1_by_threshold)\nval_max = np.max(pf1_by_threshold)\nthreshold_best = thresholds[arg_max]\nplt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n\n# Plot pF1 by Threshold\nplt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.xlim(0, 100)\nplt.ylim(0, 1)\nplt.xlabel('Threshold')\nplt.ylabel('pF1 Score')\nplt.legend(fontsize=12)\nplt.grid()\nplt.show()\nprint(f'Best Threshold {threshold_best:.2f}.')\n\nprint(f'pF1 Score: {val_max:.2f}.')\n\n# Training History","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python convext_m0.py","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile convext_m1.py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom keras_cv_attention_models import convnext\n\nimport os\nimport time\nimport pickle\nimport math\nimport random\nimport sys\nimport cv2\nimport gc\nimport datetime\n\nprint(f'Tensorflow Version: {tf.__version__}')\nprint(f'Python Version: {sys.version}')\n\n# Save Versions\n\nnow = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\nnp.save(now, np.array([now]))\n\n# Mixed Precision Policy\n\n# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n# TPU is fast enough and has enough memory to use float32\npolicy = tf.keras.mixed_precision.Policy('float32')\ntf.keras.mixed_precision.set_global_policy(policy)\n\nprint(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n\n# Matplotlib Config\n\n# MatplotLib Global Settings\nmpl.rcParams.update(mpl.rcParamsDefault)\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.labelsize'] = 18\nmpl.rcParams['axes.titlesize'] = 24\n\n# Config\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n\n#/kaggle/input/rsna-tfrecords-768x1344-dataset\n\n# For TPU's the dataset needs to be stored in Google Cloud\n# Retrieve the Google Cloud location of the dataset\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n\nSEED = 43\nDEBUG = False\nVERSION = 'convext_m1'\n# Image dimensions\nIMG_HEIGHT = 1344\nIMG_WIDTH = 768\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nLR_MAX = 5e-6 * N_REPLICAS\nWD_RATIO = 0.008\n\nN_WARMUP_EPOCHS = 0\nN_EPOCHS = 10\n\n# Batch size\nBATCH_SIZE = 8 * N_REPLICAS\n\n# Is Interactive Flag and COrresponding Verbosity Method\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')\n\n# Seed\n\n# Seed all random number generators\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()\n\n# Train\n\n# Train DataFrame\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n\n\n# Utility Functions\n\n# short Tensorflow randin integer function\ndef tf_rand_int(minval, maxval, dtype=tf.int64):\n    minval = tf.cast(minval, dtype)\n    maxval = tf.cast(maxval, dtype)\n    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n\n# chance of 1 in k\ndef one_in(k):\n    return 0 == tf_rand_int(0, k)\n\n# Dataset\n\n# Function to benchmark the dataset\ndef benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n            if idx == 0:\n                epoch_start = time.perf_counter()\n            elif idx == 1 and epoch_num == 0:\n                image = inputs['image']\n                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n            else:\n                pass\n        \n        epoch_t = time.perf_counter() - epoch_start\n        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n\n# Plots a batch of images\ndef show_batch(dataset, n_rows=16, n_cols=4):\n    inputs, targets = next(iter(dataset))\n    images = inputs['image'].numpy().squeeze()\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n    for r in range(n_rows):\n        for c in range(n_cols):\n            idx = r * n_cols + c\n            # Image\n            img = images[idx]\n            axes[r, c].imshow(img)\n            # Target\n            target = targets[idx]\n            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n        \n    plt.show()\n\n# Decodes the TFRecords\ndef decode_image(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n    })\n    \n    # Decode PNG Image\n    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n    # Explicit reshape needed for TPU\n    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n\n    target = features['target']\n    \n    return { 'image': image }, target\n\ndef augment_image(X, y):\n    image = X['image']\n    \n    # Random Brightness\n    image = tf.image.random_brightness(image, 0.10)\n    \n    # Random Contrast\n    image = tf.image.random_contrast(image, 0.90, 1.10)\n    \n    # Random JPEG Quality\n    image = tf.image.random_jpeg_quality(image, 75, 100)\n    \n    # Random crop image with maximum of 10%\n    ratio = tf.random.uniform([], 0.75, 1.00)\n    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n    # Random offset for crop\n    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n    img_width_offset = 0\n    # Crop And Resize\n    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n    # Clip pixel values in range [0,255] to prevent underflow/overflow\n    image = tf.clip_by_value(image, 0, 255)\n    image = tf.cast(image, tf.uint8)\n    \n    return { 'image': image }, y\n\n# Undersample majority class (0/negative) by randomly dropping them\ndef undersample_majority(X, y):\n    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n    return y == 1 or tf.random.uniform([]) > 0.76\n\n# TFRecord file paths\nTFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\nprint(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n\n# Train Test Split\nTFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\nTFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\nTFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL2]\nTFRECORDS_VAL = TFRECORDS_VAL2\nprint(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\ndef get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    \n    # Initialize dataset with TFRecords\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n    \n    # Decode mapping\n    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n\n    if not val:\n        dataset = dataset.filter(undersample_majority)\n        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n        dataset = dataset.with_options(ignore_order)\n        if not debug:\n            dataset = dataset.shuffle(1024)\n        dataset = dataset.repeat()        \n\n    dataset = dataset.batch(bs, drop_remainder=not val)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset\n\n# Get Train/Validation datasets\ntrain_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\nval_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n\nTRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nVAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nprint(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n\n# Sanity check, image and label statistics\nX_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\nimage = X_batch['image'].numpy()\nprint(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\nprint(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\nprint(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n\n# Benchmark Dataset\nbenchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n\n# Show what we will be training on\nshow_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n\n# Tensorflow custom metric is just a conventional class object\nclass pF1(tf.keras.metrics.Metric):\n    # Initialize properties\n    def __init__(self, name='pF1', **kwargs):\n        super(pF1, self).__init__(name=name, **kwargs)\n        self.tc = self.add_weight(name='tc', initializer='zeros')\n        self.tp = self.add_weight(name='tp', initializer='zeros')\n        self.fp = self.add_weight(name='fp', initializer='zeros')\n\n    # Update state called on each batch with true and predicted labels\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n\n    # Result function is called to obtain result which is printed in progress bar\n    def result(self):\n        if self.tc == 0 or (self.tp + self.fp) == 0:\n            return 0.0\n        else:\n            precision = self.tp / (self.tp + self.fp)\n            recall = self.tp / (self.tc)\n            return 2 * (precision * recall) / (precision + recall)\n\n    # Reset state is called after each epoch to start fresh each epoch\n    def reset_state(self):\n        self.tc.assign(0)\n        self.tp.assign(0)\n        self.fp.assign(0)\n\ndef normalize(image):\n    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n    image = tf.repeat(image, repeats=3, axis=3)\n    # Cast to float 32\n    image = tf.cast(image, tf.float32)\n    # Normalize with respect to ImageNet mean/std\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image\n\ndef get_model():\n    # Verify Mixed Policy Settings\n    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n    \n    with STRATEGY.scope():\n        # Set seed for deterministic weights initialization\n        seed_everything()\n        \n        # Inputs, note the names are equal to the dictionary keys in the dataset\n        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n        \n        # Normalize Input\n        image_norm = normalize(image)\n\n        # CNN Prediction in range [0,1]\n        x = convnext.ConvNeXtV2Tiny(\n            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n            pretrained='imagenet21k-ft1k',\n            num_classes=0,\n        )(image_norm)\n        \n        # Average Pooling BxHxWxC -> BxC\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        # Dropout to prevent Overfitting\n        x = tf.keras.layers.Dropout(0.30)(x)\n        # Output value between [0, 1] using Sigmoid function\n        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n        # We will use the famous AdamW optimizer for fast learning with weight decay\n        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n\n        # Loss\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n        \n        # Metrics\n        metrics = [\n            pF1(),\n            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n            tf.keras.metrics.Precision(),\n            tf.keras.metrics.Recall(),\n            tf.keras.metrics.AUC(),\n            tf.keras.metrics.BinaryAccuracy(),\n        ]\n\n        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n        \n        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n        return model\n\n# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\ntf.keras.backend.clear_session()\n# enable XLA optmizations\ntf.config.optimizer.set_jit(True)\n\nmodel = get_model()\n\n# Weight Initilization\n\n# Validation metric on initialized model\n_ = model.evaluate(\n        get_dataset(TFRECORDS_VAL, val=True),\n        verbose=VERBOSE,\n        steps=VAL_STEPS_PER_EPOCH,\n    )\n\n# Learning rate scheduler with logaritmic warmup and cosine decay\ndef lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n    \n    if current_step < num_warmup_steps:\n        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n\n# Plot the learning rate scheduler\ndef plot_lr_schedule(lr_schedule, epochs):\n    fig = plt.figure(figsize=(20, 10))\n    plt.plot([None] + lr_schedule + [None])\n    # X Labels\n    x = np.arange(1, epochs + 1)\n    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n    plt.xlim([1, epochs])\n    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n    \n    # Increase y-limit for better readability\n    plt.ylim([0, max(lr_schedule) * 1.1])\n    \n    # Title\n    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n    \n    # Plot Learning Rates\n    for x, val in enumerate(lr_schedule):\n        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n            if x < len(lr_schedule) - 1:\n                if lr_schedule[x - 1] < val:\n                    ha = 'right'\n                else:\n                    ha = 'left'\n            elif x == 0:\n                ha = 'right'\n            else:\n                ha = 'left'\n            plt.plot(x + 1, val, 'o', color='black');\n            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n    \n    plt.xlabel('Epoch', size=16, labelpad=5)\n    plt.ylabel('Learning Rate', size=16, labelpad=5)\n    plt.grid()\n    plt.show()\n\n# Learning rate for encoder\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\nplot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n\n# Learning Rate Callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n\n# Weight Decay Callback\n\n# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\nclass WeightDecayCallback(tf.keras.callbacks.Callback):\n    def __init__(self, wd_ratio=WD_RATIO):\n        self.step_counter = 0\n        self.wd_ratio = wd_ratio\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n\n# Train model on TPU!\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=f'best_{VERSION}.h5',\n    save_weights_only=True,\n    monitor='val_pF1',\n    mode='max',\n    save_best_only=True)\nhistory = model.fit(\n        train_dataset,\n        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n        validation_data = val_dataset,\n        epochs = N_EPOCHS,\n        verbose = VERBOSE,\n        callbacks = [\n            model_checkpoint_callback,\n            lr_callback,\n            WeightDecayCallback(),\n        ],\n        class_weight = {\n            0: 1.0,\n            1: 5.0,\n        },\n    )\n\n# Save model weights for inference\nmodel.save_weights(f'model_{VERSION}.h5')\n\n# F1 By Threshold\n\n# Get true labels and predictions for validation set\ny_true_val = []\ny_pred_val = []\nfor X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n    y_true_val += y_batch.numpy().tolist()\n    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n\n# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n# Competition Leaderboard Metric\ndef pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0\n\n# Plot pF1 by threshold plot to find best threshold\npf1_by_threshold = []\nthresholds = np.arange(0, 1.01, 0.01)\nfor t in tqdm(thresholds):\n    # Compute pF1 for each threshold\n    pf1_by_threshold.append(\n        pfbeta(y_true_val, y_pred_val > t)\n    )\n    \nplt.figure(figsize=(15,8))\nplt.title('F1 By Threshold', size=24)\nplt.plot(pf1_by_threshold, label='F1 Score')\n\n# Best threshold and pF1 score\narg_max = np.argmax(pf1_by_threshold)\nval_max = np.max(pf1_by_threshold)\nthreshold_best = thresholds[arg_max]\nplt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n\n# Plot pF1 by Threshold\nplt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.xlim(0, 100)\nplt.ylim(0, 1)\nplt.xlabel('Threshold')\nplt.ylabel('pF1 Score')\nplt.legend(fontsize=12)\nplt.grid()\nplt.show()\nprint(f'Best Threshold {threshold_best:.2f}.')\n\nprint(f'pF1 Score: {val_max:.2f}.')\n\n# Training History","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python convext_m1.py","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile convext_m2.py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom keras_cv_attention_models import convnext\n\nimport os\nimport time\nimport pickle\nimport math\nimport random\nimport sys\nimport cv2\nimport gc\nimport datetime\n\nprint(f'Tensorflow Version: {tf.__version__}')\nprint(f'Python Version: {sys.version}')\n\n# Save Versions\n\nnow = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\nnp.save(now, np.array([now]))\n\n# Mixed Precision Policy\n\n# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n# TPU is fast enough and has enough memory to use float32\npolicy = tf.keras.mixed_precision.Policy('float32')\ntf.keras.mixed_precision.set_global_policy(policy)\n\nprint(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n\n# Matplotlib Config\n\n# MatplotLib Global Settings\nmpl.rcParams.update(mpl.rcParamsDefault)\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.labelsize'] = 18\nmpl.rcParams['axes.titlesize'] = 24\n\n# Config\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n\n#/kaggle/input/rsna-tfrecords-768x1344-dataset\n\n# For TPU's the dataset needs to be stored in Google Cloud\n# Retrieve the Google Cloud location of the dataset\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n\nSEED = 43\nDEBUG = False\nVERSION = 'convext_m2'\n# Image dimensions\nIMG_HEIGHT = 1344\nIMG_WIDTH = 768\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nLR_MAX = 5e-6 * N_REPLICAS\nWD_RATIO = 0.008\n\nN_WARMUP_EPOCHS = 0\nN_EPOCHS = 10\n\n# Batch size\nBATCH_SIZE = 8 * N_REPLICAS\n\n# Is Interactive Flag and COrresponding Verbosity Method\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')\n\n# Seed\n\n# Seed all random number generators\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()\n\n# Train\n\n# Train DataFrame\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n\n\n# Utility Functions\n\n# short Tensorflow randin integer function\ndef tf_rand_int(minval, maxval, dtype=tf.int64):\n    minval = tf.cast(minval, dtype)\n    maxval = tf.cast(maxval, dtype)\n    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n\n# chance of 1 in k\ndef one_in(k):\n    return 0 == tf_rand_int(0, k)\n\n# Dataset\n\n# Function to benchmark the dataset\ndef benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n            if idx == 0:\n                epoch_start = time.perf_counter()\n            elif idx == 1 and epoch_num == 0:\n                image = inputs['image']\n                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n            else:\n                pass\n        \n        epoch_t = time.perf_counter() - epoch_start\n        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n\n# Plots a batch of images\ndef show_batch(dataset, n_rows=16, n_cols=4):\n    inputs, targets = next(iter(dataset))\n    images = inputs['image'].numpy().squeeze()\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n    for r in range(n_rows):\n        for c in range(n_cols):\n            idx = r * n_cols + c\n            # Image\n            img = images[idx]\n            axes[r, c].imshow(img)\n            # Target\n            target = targets[idx]\n            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n        \n    plt.show()\n\n# Decodes the TFRecords\ndef decode_image(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n    })\n    \n    # Decode PNG Image\n    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n    # Explicit reshape needed for TPU\n    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n\n    target = features['target']\n    \n    return { 'image': image }, target\n\ndef augment_image(X, y):\n    image = X['image']\n    \n    # Random Brightness\n    image = tf.image.random_brightness(image, 0.10)\n    \n    # Random Contrast\n    image = tf.image.random_contrast(image, 0.90, 1.10)\n    \n    # Random JPEG Quality\n    image = tf.image.random_jpeg_quality(image, 75, 100)\n    \n    # Random crop image with maximum of 10%\n    ratio = tf.random.uniform([], 0.75, 1.00)\n    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n    # Random offset for crop\n    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n    img_width_offset = 0\n    # Crop And Resize\n    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n    # Clip pixel values in range [0,255] to prevent underflow/overflow\n    image = tf.clip_by_value(image, 0, 255)\n    image = tf.cast(image, tf.uint8)\n    \n    return { 'image': image }, y\n\n# Undersample majority class (0/negative) by randomly dropping them\ndef undersample_majority(X, y):\n    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n    return y == 1 or tf.random.uniform([]) > 0.76\n\n# TFRecord file paths\nTFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\nprint(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n\n# Train Test Split\nTFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\nTFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\nTFRECORDS_TRAIN3, TFRECORDS_VAL3 = train_test_split(TFRECORDS_TRAIN2, train_size=0.67, random_state=SEED, shuffle=True)\n\nTFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL3]\nTFRECORDS_VAL = TFRECORDS_VAL3\nprint(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\ndef get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    \n    # Initialize dataset with TFRecords\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n    \n    # Decode mapping\n    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n\n    if not val:\n        dataset = dataset.filter(undersample_majority)\n        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n        dataset = dataset.with_options(ignore_order)\n        if not debug:\n            dataset = dataset.shuffle(1024)\n        dataset = dataset.repeat()        \n\n    dataset = dataset.batch(bs, drop_remainder=not val)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset\n\n# Get Train/Validation datasets\ntrain_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\nval_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n\nTRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nVAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nprint(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n\n# Sanity check, image and label statistics\nX_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\nimage = X_batch['image'].numpy()\nprint(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\nprint(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\nprint(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n\n# Benchmark Dataset\nbenchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n\n# Show what we will be training on\nshow_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n\n# Tensorflow custom metric is just a conventional class object\nclass pF1(tf.keras.metrics.Metric):\n    # Initialize properties\n    def __init__(self, name='pF1', **kwargs):\n        super(pF1, self).__init__(name=name, **kwargs)\n        self.tc = self.add_weight(name='tc', initializer='zeros')\n        self.tp = self.add_weight(name='tp', initializer='zeros')\n        self.fp = self.add_weight(name='fp', initializer='zeros')\n\n    # Update state called on each batch with true and predicted labels\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n\n    # Result function is called to obtain result which is printed in progress bar\n    def result(self):\n        if self.tc == 0 or (self.tp + self.fp) == 0:\n            return 0.0\n        else:\n            precision = self.tp / (self.tp + self.fp)\n            recall = self.tp / (self.tc)\n            return 2 * (precision * recall) / (precision + recall)\n\n    # Reset state is called after each epoch to start fresh each epoch\n    def reset_state(self):\n        self.tc.assign(0)\n        self.tp.assign(0)\n        self.fp.assign(0)\n\ndef normalize(image):\n    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n    image = tf.repeat(image, repeats=3, axis=3)\n    # Cast to float 32\n    image = tf.cast(image, tf.float32)\n    # Normalize with respect to ImageNet mean/std\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image\n\ndef get_model():\n    # Verify Mixed Policy Settings\n    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n    \n    with STRATEGY.scope():\n        # Set seed for deterministic weights initialization\n        seed_everything()\n        \n        # Inputs, note the names are equal to the dictionary keys in the dataset\n        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n        \n        # Normalize Input\n        image_norm = normalize(image)\n\n        # CNN Prediction in range [0,1]\n        x = convnext.ConvNeXtV2Tiny(\n            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n            pretrained='imagenet21k-ft1k',\n            num_classes=0,\n        )(image_norm)\n        \n        # Average Pooling BxHxWxC -> BxC\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        # Dropout to prevent Overfitting\n        x = tf.keras.layers.Dropout(0.30)(x)\n        # Output value between [0, 1] using Sigmoid function\n        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n        # We will use the famous AdamW optimizer for fast learning with weight decay\n        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n\n        # Loss\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n        \n        # Metrics\n        metrics = [\n            pF1(),\n            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n            tf.keras.metrics.Precision(),\n            tf.keras.metrics.Recall(),\n            tf.keras.metrics.AUC(),\n            tf.keras.metrics.BinaryAccuracy(),\n        ]\n\n        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n        \n        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n        return model\n\n# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\ntf.keras.backend.clear_session()\n# enable XLA optmizations\ntf.config.optimizer.set_jit(True)\n\nmodel = get_model()\n\n# Weight Initilization\n\n# Validation metric on initialized model\n_ = model.evaluate(\n        get_dataset(TFRECORDS_VAL, val=True),\n        verbose=VERBOSE,\n        steps=VAL_STEPS_PER_EPOCH,\n    )\n\n# Learning rate scheduler with logaritmic warmup and cosine decay\ndef lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n    \n    if current_step < num_warmup_steps:\n        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n\n# Plot the learning rate scheduler\ndef plot_lr_schedule(lr_schedule, epochs):\n    fig = plt.figure(figsize=(20, 10))\n    plt.plot([None] + lr_schedule + [None])\n    # X Labels\n    x = np.arange(1, epochs + 1)\n    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n    plt.xlim([1, epochs])\n    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n    \n    # Increase y-limit for better readability\n    plt.ylim([0, max(lr_schedule) * 1.1])\n    \n    # Title\n    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n    \n    # Plot Learning Rates\n    for x, val in enumerate(lr_schedule):\n        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n            if x < len(lr_schedule) - 1:\n                if lr_schedule[x - 1] < val:\n                    ha = 'right'\n                else:\n                    ha = 'left'\n            elif x == 0:\n                ha = 'right'\n            else:\n                ha = 'left'\n            plt.plot(x + 1, val, 'o', color='black');\n            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n    \n    plt.xlabel('Epoch', size=16, labelpad=5)\n    plt.ylabel('Learning Rate', size=16, labelpad=5)\n    plt.grid()\n    plt.show()\n\n# Learning rate for encoder\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\nplot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n\n# Learning Rate Callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n\n# Weight Decay Callback\n\n# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\nclass WeightDecayCallback(tf.keras.callbacks.Callback):\n    def __init__(self, wd_ratio=WD_RATIO):\n        self.step_counter = 0\n        self.wd_ratio = wd_ratio\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n\n# Train model on TPU!\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=f'best_{VERSION}.h5',\n    save_weights_only=True,\n    monitor='val_pF1',\n    mode='max',\n    save_best_only=True)\nhistory = model.fit(\n        train_dataset,\n        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n        validation_data = val_dataset,\n        epochs = N_EPOCHS,\n        verbose = VERBOSE,\n        callbacks = [\n            model_checkpoint_callback,\n            lr_callback,\n            WeightDecayCallback(),\n        ],\n        class_weight = {\n            0: 1.0,\n            1: 5.0,\n        },\n    )\n\n# Save model weights for inference\nmodel.save_weights(f'model_{VERSION}.h5')\n\n# F1 By Threshold\n\n# Get true labels and predictions for validation set\ny_true_val = []\ny_pred_val = []\nfor X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n    y_true_val += y_batch.numpy().tolist()\n    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n\n# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n# Competition Leaderboard Metric\ndef pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0\n\n# Plot pF1 by threshold plot to find best threshold\npf1_by_threshold = []\nthresholds = np.arange(0, 1.01, 0.01)\nfor t in tqdm(thresholds):\n    # Compute pF1 for each threshold\n    pf1_by_threshold.append(\n        pfbeta(y_true_val, y_pred_val > t)\n    )\n    \nplt.figure(figsize=(15,8))\nplt.title('F1 By Threshold', size=24)\nplt.plot(pf1_by_threshold, label='F1 Score')\n\n# Best threshold and pF1 score\narg_max = np.argmax(pf1_by_threshold)\nval_max = np.max(pf1_by_threshold)\nthreshold_best = thresholds[arg_max]\nplt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n\n# Plot pF1 by Threshold\nplt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.xlim(0, 100)\nplt.ylim(0, 1)\nplt.xlabel('Threshold')\nplt.ylabel('pF1 Score')\nplt.legend(fontsize=12)\nplt.grid()\nplt.show()\nprint(f'Best Threshold {threshold_best:.2f}.')\n\nprint(f'pF1 Score: {val_max:.2f}.')\n\n# Training History","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python convext_m2.py","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile convext_m3.py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom keras_cv_attention_models import convnext\n\nimport os\nimport time\nimport pickle\nimport math\nimport random\nimport sys\nimport cv2\nimport gc\nimport datetime\n\nprint(f'Tensorflow Version: {tf.__version__}')\nprint(f'Python Version: {sys.version}')\n\n# Save Versions\n\nnow = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\nnp.save(now, np.array([now]))\n\n# Mixed Precision Policy\n\n# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n# TPU is fast enough and has enough memory to use float32\npolicy = tf.keras.mixed_precision.Policy('float32')\ntf.keras.mixed_precision.set_global_policy(policy)\n\nprint(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n\n# Matplotlib Config\n\n# MatplotLib Global Settings\nmpl.rcParams.update(mpl.rcParamsDefault)\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.labelsize'] = 18\nmpl.rcParams['axes.titlesize'] = 24\n\n# Config\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n\n#/kaggle/input/rsna-tfrecords-768x1344-dataset\n\n# For TPU's the dataset needs to be stored in Google Cloud\n# Retrieve the Google Cloud location of the dataset\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n\nSEED = 43\nDEBUG = False\nVERSION = 'convext_m3'\n# Image dimensions\nIMG_HEIGHT = 1344\nIMG_WIDTH = 768\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nLR_MAX = 5e-6 * N_REPLICAS\nWD_RATIO = 0.008\n\nN_WARMUP_EPOCHS = 0\nN_EPOCHS = 10\n\n# Batch size\nBATCH_SIZE = 8 * N_REPLICAS\n\n# Is Interactive Flag and COrresponding Verbosity Method\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')\n\n# Seed\n\n# Seed all random number generators\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()\n\n# Train\n\n# Train DataFrame\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n\n\n# Utility Functions\n\n# short Tensorflow randin integer function\ndef tf_rand_int(minval, maxval, dtype=tf.int64):\n    minval = tf.cast(minval, dtype)\n    maxval = tf.cast(maxval, dtype)\n    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n\n# chance of 1 in k\ndef one_in(k):\n    return 0 == tf_rand_int(0, k)\n\n# Dataset\n\n# Function to benchmark the dataset\ndef benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n            if idx == 0:\n                epoch_start = time.perf_counter()\n            elif idx == 1 and epoch_num == 0:\n                image = inputs['image']\n                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n            else:\n                pass\n        \n        epoch_t = time.perf_counter() - epoch_start\n        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n\n# Plots a batch of images\ndef show_batch(dataset, n_rows=16, n_cols=4):\n    inputs, targets = next(iter(dataset))\n    images = inputs['image'].numpy().squeeze()\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n    for r in range(n_rows):\n        for c in range(n_cols):\n            idx = r * n_cols + c\n            # Image\n            img = images[idx]\n            axes[r, c].imshow(img)\n            # Target\n            target = targets[idx]\n            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n        \n    plt.show()\n\n# Decodes the TFRecords\ndef decode_image(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n    })\n    \n    # Decode PNG Image\n    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n    # Explicit reshape needed for TPU\n    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n\n    target = features['target']\n    \n    return { 'image': image }, target\n\ndef augment_image(X, y):\n    image = X['image']\n    \n    # Random Brightness\n    image = tf.image.random_brightness(image, 0.10)\n    \n    # Random Contrast\n    image = tf.image.random_contrast(image, 0.90, 1.10)\n    \n    # Random JPEG Quality\n    image = tf.image.random_jpeg_quality(image, 75, 100)\n    \n    # Random crop image with maximum of 10%\n    ratio = tf.random.uniform([], 0.75, 1.00)\n    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n    # Random offset for crop\n    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n    img_width_offset = 0\n    # Crop And Resize\n    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n    # Clip pixel values in range [0,255] to prevent underflow/overflow\n    image = tf.clip_by_value(image, 0, 255)\n    image = tf.cast(image, tf.uint8)\n    \n    return { 'image': image }, y\n\n# Undersample majority class (0/negative) by randomly dropping them\ndef undersample_majority(X, y):\n    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n    return y == 1 or tf.random.uniform([]) > 0.76\n\n# TFRecord file paths\nTFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\nprint(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n\n# Train Test Split\nTFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\nTFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\nTFRECORDS_TRAIN3, TFRECORDS_VAL3 = train_test_split(TFRECORDS_TRAIN2, train_size=0.67, random_state=SEED, shuffle=True)\nTFRECORDS_TRAIN4, TFRECORDS_VAL4 = train_test_split(TFRECORDS_TRAIN3, train_size=0.5, random_state=SEED, shuffle=True)\n\nTFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_VAL4]\nTFRECORDS_VAL = TFRECORDS_VAL4\nprint(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\ndef get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    \n    # Initialize dataset with TFRecords\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n    \n    # Decode mapping\n    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n\n    if not val:\n        dataset = dataset.filter(undersample_majority)\n        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n        dataset = dataset.with_options(ignore_order)\n        if not debug:\n            dataset = dataset.shuffle(1024)\n        dataset = dataset.repeat()        \n\n    dataset = dataset.batch(bs, drop_remainder=not val)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset\n\n# Get Train/Validation datasets\ntrain_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\nval_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n\nTRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nVAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nprint(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n\n# Sanity check, image and label statistics\nX_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\nimage = X_batch['image'].numpy()\nprint(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\nprint(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\nprint(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n\n# Benchmark Dataset\nbenchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n\n# Show what we will be training on\nshow_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n\n# Tensorflow custom metric is just a conventional class object\nclass pF1(tf.keras.metrics.Metric):\n    # Initialize properties\n    def __init__(self, name='pF1', **kwargs):\n        super(pF1, self).__init__(name=name, **kwargs)\n        self.tc = self.add_weight(name='tc', initializer='zeros')\n        self.tp = self.add_weight(name='tp', initializer='zeros')\n        self.fp = self.add_weight(name='fp', initializer='zeros')\n\n    # Update state called on each batch with true and predicted labels\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n\n    # Result function is called to obtain result which is printed in progress bar\n    def result(self):\n        if self.tc == 0 or (self.tp + self.fp) == 0:\n            return 0.0\n        else:\n            precision = self.tp / (self.tp + self.fp)\n            recall = self.tp / (self.tc)\n            return 2 * (precision * recall) / (precision + recall)\n\n    # Reset state is called after each epoch to start fresh each epoch\n    def reset_state(self):\n        self.tc.assign(0)\n        self.tp.assign(0)\n        self.fp.assign(0)\n\ndef normalize(image):\n    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n    image = tf.repeat(image, repeats=3, axis=3)\n    # Cast to float 32\n    image = tf.cast(image, tf.float32)\n    # Normalize with respect to ImageNet mean/std\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image\n\ndef get_model():\n    # Verify Mixed Policy Settings\n    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n    \n    with STRATEGY.scope():\n        # Set seed for deterministic weights initialization\n        seed_everything()\n        \n        # Inputs, note the names are equal to the dictionary keys in the dataset\n        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n        \n        # Normalize Input\n        image_norm = normalize(image)\n\n        # CNN Prediction in range [0,1]\n        x = convnext.ConvNeXtV2Tiny(\n            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n            pretrained='imagenet21k-ft1k',\n            num_classes=0,\n        )(image_norm)\n        \n        # Average Pooling BxHxWxC -> BxC\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        # Dropout to prevent Overfitting\n        x = tf.keras.layers.Dropout(0.30)(x)\n        # Output value between [0, 1] using Sigmoid function\n        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n        # We will use the famous AdamW optimizer for fast learning with weight decay\n        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n\n        # Loss\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n        \n        # Metrics\n        metrics = [\n            pF1(),\n            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n            tf.keras.metrics.Precision(),\n            tf.keras.metrics.Recall(),\n            tf.keras.metrics.AUC(),\n            tf.keras.metrics.BinaryAccuracy(),\n        ]\n\n        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n        \n        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n        return model\n\n# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\ntf.keras.backend.clear_session()\n# enable XLA optmizations\ntf.config.optimizer.set_jit(True)\n\nmodel = get_model()\n\n# Weight Initilization\n\n# Validation metric on initialized model\n_ = model.evaluate(\n        get_dataset(TFRECORDS_VAL, val=True),\n        verbose=VERBOSE,\n        steps=VAL_STEPS_PER_EPOCH,\n    )\n\n# Learning rate scheduler with logaritmic warmup and cosine decay\ndef lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n    \n    if current_step < num_warmup_steps:\n        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n\n# Plot the learning rate scheduler\ndef plot_lr_schedule(lr_schedule, epochs):\n    fig = plt.figure(figsize=(20, 10))\n    plt.plot([None] + lr_schedule + [None])\n    # X Labels\n    x = np.arange(1, epochs + 1)\n    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n    plt.xlim([1, epochs])\n    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n    \n    # Increase y-limit for better readability\n    plt.ylim([0, max(lr_schedule) * 1.1])\n    \n    # Title\n    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n    \n    # Plot Learning Rates\n    for x, val in enumerate(lr_schedule):\n        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n            if x < len(lr_schedule) - 1:\n                if lr_schedule[x - 1] < val:\n                    ha = 'right'\n                else:\n                    ha = 'left'\n            elif x == 0:\n                ha = 'right'\n            else:\n                ha = 'left'\n            plt.plot(x + 1, val, 'o', color='black');\n            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n    \n    plt.xlabel('Epoch', size=16, labelpad=5)\n    plt.ylabel('Learning Rate', size=16, labelpad=5)\n    plt.grid()\n    plt.show()\n\n# Learning rate for encoder\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\nplot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n\n# Learning Rate Callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n\n# Weight Decay Callback\n\n# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\nclass WeightDecayCallback(tf.keras.callbacks.Callback):\n    def __init__(self, wd_ratio=WD_RATIO):\n        self.step_counter = 0\n        self.wd_ratio = wd_ratio\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n\n# Train model on TPU!\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=f'best_{VERSION}.h5',\n    save_weights_only=True,\n    monitor='val_pF1',\n    mode='max',\n    save_best_only=True)\nhistory = model.fit(\n        train_dataset,\n        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n        validation_data = val_dataset,\n        epochs = N_EPOCHS,\n        verbose = VERBOSE,\n        callbacks = [\n            model_checkpoint_callback,\n            lr_callback,\n            WeightDecayCallback(),\n        ],\n        class_weight = {\n            0: 1.0,\n            1: 5.0,\n        },\n    )\n\n# Save model weights for inference\nmodel.save_weights(f'model_{VERSION}.h5')\n\n# F1 By Threshold\n\n# Get true labels and predictions for validation set\ny_true_val = []\ny_pred_val = []\nfor X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n    y_true_val += y_batch.numpy().tolist()\n    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n\n# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n# Competition Leaderboard Metric\ndef pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0\n\n# Plot pF1 by threshold plot to find best threshold\npf1_by_threshold = []\nthresholds = np.arange(0, 1.01, 0.01)\nfor t in tqdm(thresholds):\n    # Compute pF1 for each threshold\n    pf1_by_threshold.append(\n        pfbeta(y_true_val, y_pred_val > t)\n    )\n    \nplt.figure(figsize=(15,8))\nplt.title('F1 By Threshold', size=24)\nplt.plot(pf1_by_threshold, label='F1 Score')\n\n# Best threshold and pF1 score\narg_max = np.argmax(pf1_by_threshold)\nval_max = np.max(pf1_by_threshold)\nthreshold_best = thresholds[arg_max]\nplt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n\n# Plot pF1 by Threshold\nplt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.xlim(0, 100)\nplt.ylim(0, 1)\nplt.xlabel('Threshold')\nplt.ylabel('pF1 Score')\nplt.legend(fontsize=12)\nplt.grid()\nplt.show()\nprint(f'Best Threshold {threshold_best:.2f}.')\n\nprint(f'pF1 Score: {val_max:.2f}.')\n\n# Training History","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python convext_m3.py","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile convext_m4.py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom keras_cv_attention_models import convnext\n\nimport os\nimport time\nimport pickle\nimport math\nimport random\nimport sys\nimport cv2\nimport gc\nimport datetime\n\nprint(f'Tensorflow Version: {tf.__version__}')\nprint(f'Python Version: {sys.version}')\n\n# Save Versions\n\nnow = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\nnp.save(now, np.array([now]))\n\n# Mixed Precision Policy\n\n# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n# TPU is fast enough and has enough memory to use float32\npolicy = tf.keras.mixed_precision.Policy('float32')\ntf.keras.mixed_precision.set_global_policy(policy)\n\nprint(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n\n# Matplotlib Config\n\n# MatplotLib Global Settings\nmpl.rcParams.update(mpl.rcParamsDefault)\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.labelsize'] = 18\nmpl.rcParams['axes.titlesize'] = 24\n\n# Config\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n\n#/kaggle/input/rsna-tfrecords-768x1344-dataset\n\n# For TPU's the dataset needs to be stored in Google Cloud\n# Retrieve the Google Cloud location of the dataset\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-tfrecords-768x1344-dataset2')\n\nSEED = 43\nDEBUG = False\nVERSION = 'convext_m4'\n# Image dimensions\nIMG_HEIGHT = 1344\nIMG_WIDTH = 768\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nLR_MAX = 5e-6 * N_REPLICAS\nWD_RATIO = 0.008\n\nN_WARMUP_EPOCHS = 0\nN_EPOCHS = 10\n\n# Batch size\nBATCH_SIZE = 8 * N_REPLICAS\n\n# Is Interactive Flag and COrresponding Verbosity Method\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')\n\n# Seed\n\n# Seed all random number generators\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()\n\n# Train\n\n# Train DataFrame\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n\n\n# Utility Functions\n\n# short Tensorflow randin integer function\ndef tf_rand_int(minval, maxval, dtype=tf.int64):\n    minval = tf.cast(minval, dtype)\n    maxval = tf.cast(maxval, dtype)\n    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n\n# chance of 1 in k\ndef one_in(k):\n    return 0 == tf_rand_int(0, k)\n\n# Dataset\n\n# Function to benchmark the dataset\ndef benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n            if idx == 0:\n                epoch_start = time.perf_counter()\n            elif idx == 1 and epoch_num == 0:\n                image = inputs['image']\n                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n            else:\n                pass\n        \n        epoch_t = time.perf_counter() - epoch_start\n        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n\n# Plots a batch of images\ndef show_batch(dataset, n_rows=16, n_cols=4):\n    inputs, targets = next(iter(dataset))\n    images = inputs['image'].numpy().squeeze()\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n    for r in range(n_rows):\n        for c in range(n_cols):\n            idx = r * n_cols + c\n            # Image\n            img = images[idx]\n            axes[r, c].imshow(img)\n            # Target\n            target = targets[idx]\n            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n        \n    plt.show()\n\n# Decodes the TFRecords\ndef decode_image(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n    })\n    \n    # Decode PNG Image\n    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n    # Explicit reshape needed for TPU\n    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n\n    target = features['target']\n    \n    return { 'image': image }, target\n\ndef augment_image(X, y):\n    image = X['image']\n    \n    # Random Brightness\n    image = tf.image.random_brightness(image, 0.10)\n    \n    # Random Contrast\n    image = tf.image.random_contrast(image, 0.90, 1.10)\n    \n    # Random JPEG Quality\n    image = tf.image.random_jpeg_quality(image, 75, 100)\n    \n    # Random crop image with maximum of 10%\n    ratio = tf.random.uniform([], 0.75, 1.00)\n    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n    # Random offset for crop\n    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n    img_width_offset = 0\n    # Crop And Resize\n    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n    # Clip pixel values in range [0,255] to prevent underflow/overflow\n    image = tf.clip_by_value(image, 0, 255)\n    image = tf.cast(image, tf.uint8)\n    \n    return { 'image': image }, y\n\n# Undersample majority class (0/negative) by randomly dropping them\ndef undersample_majority(X, y):\n    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n    return y == 1 or tf.random.uniform([]) > 0.76\n\n# TFRecord file paths\nTFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\nprint(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')\n\n# Train Test Split\nTFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\nTFRECORDS_TRAIN2, TFRECORDS_VAL2 = train_test_split(TFRECORDS_TRAIN, train_size=0.75, random_state=SEED, shuffle=True)\n#print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN2)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL2)}')\nTFRECORDS_TRAIN3, TFRECORDS_VAL3 = train_test_split(TFRECORDS_TRAIN2, train_size=0.67, random_state=SEED, shuffle=True)\nTFRECORDS_TRAIN4, TFRECORDS_VAL4 = train_test_split(TFRECORDS_TRAIN3, train_size=0.5, random_state=SEED, shuffle=True)\n\nTFRECORDS_TRAIN = [x  for x in TFRECORDS_FILE_PATHS if x not in TFRECORDS_TRAIN4]\nTFRECORDS_VAL = TFRECORDS_TRAIN4\nprint(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')\ndef get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    \n    # Initialize dataset with TFRecords\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n    \n    # Decode mapping\n    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n\n    if not val:\n        dataset = dataset.filter(undersample_majority)\n        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n        dataset = dataset.with_options(ignore_order)\n        if not debug:\n            dataset = dataset.shuffle(1024)\n        dataset = dataset.repeat()        \n\n    dataset = dataset.batch(bs, drop_remainder=not val)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset\n\n# Get Train/Validation datasets\ntrain_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\nval_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n\nTRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nVAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nprint(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')\n\n# Sanity check, image and label statistics\nX_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\nimage = X_batch['image'].numpy()\nprint(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\nprint(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\nprint(f'image min: {image.min():.2f}, max: {image.max():.2f}')\n\n# Benchmark Dataset\nbenchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))\n\n# Show what we will be training on\nshow_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))\n\n# Tensorflow custom metric is just a conventional class object\nclass pF1(tf.keras.metrics.Metric):\n    # Initialize properties\n    def __init__(self, name='pF1', **kwargs):\n        super(pF1, self).__init__(name=name, **kwargs)\n        self.tc = self.add_weight(name='tc', initializer='zeros')\n        self.tp = self.add_weight(name='tp', initializer='zeros')\n        self.fp = self.add_weight(name='fp', initializer='zeros')\n\n    # Update state called on each batch with true and predicted labels\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n\n    # Result function is called to obtain result which is printed in progress bar\n    def result(self):\n        if self.tc == 0 or (self.tp + self.fp) == 0:\n            return 0.0\n        else:\n            precision = self.tp / (self.tp + self.fp)\n            recall = self.tp / (self.tc)\n            return 2 * (precision * recall) / (precision + recall)\n\n    # Reset state is called after each epoch to start fresh each epoch\n    def reset_state(self):\n        self.tc.assign(0)\n        self.tp.assign(0)\n        self.fp.assign(0)\n\ndef normalize(image):\n    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n    image = tf.repeat(image, repeats=3, axis=3)\n    # Cast to float 32\n    image = tf.cast(image, tf.float32)\n    # Normalize with respect to ImageNet mean/std\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image\n\ndef get_model():\n    # Verify Mixed Policy Settings\n    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n    \n    with STRATEGY.scope():\n        # Set seed for deterministic weights initialization\n        seed_everything()\n        \n        # Inputs, note the names are equal to the dictionary keys in the dataset\n        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n        \n        # Normalize Input\n        image_norm = normalize(image)\n\n        # CNN Prediction in range [0,1]\n        x = convnext.ConvNeXtV2Tiny(\n            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n            pretrained='imagenet21k-ft1k',\n            num_classes=0,\n        )(image_norm)\n        \n        # Average Pooling BxHxWxC -> BxC\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        # Dropout to prevent Overfitting\n        x = tf.keras.layers.Dropout(0.30)(x)\n        # Output value between [0, 1] using Sigmoid function\n        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n        # We will use the famous AdamW optimizer for fast learning with weight decay\n        optimizer = tfa.optimizers.AdamW(learning_rate=LR_MAX, weight_decay=LR_MAX*WD_RATIO, epsilon=1e-6)\n\n        # Loss\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n        \n        # Metrics\n        metrics = [\n            pF1(),\n            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n            tf.keras.metrics.Precision(),\n            tf.keras.metrics.Recall(),\n            tf.keras.metrics.AUC(),\n            tf.keras.metrics.BinaryAccuracy(),\n        ]\n\n        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n        \n        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n        return model\n\n# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\ntf.keras.backend.clear_session()\n# enable XLA optmizations\ntf.config.optimizer.set_jit(True)\n\nmodel = get_model()\n\n# Weight Initilization\n\n# Validation metric on initialized model\n_ = model.evaluate(\n        get_dataset(TFRECORDS_VAL, val=True),\n        verbose=VERBOSE,\n        steps=VAL_STEPS_PER_EPOCH,\n    )\n\n# Learning rate scheduler with logaritmic warmup and cosine decay\ndef lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n    \n    if current_step < num_warmup_steps:\n        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n\n# Plot the learning rate scheduler\ndef plot_lr_schedule(lr_schedule, epochs):\n    fig = plt.figure(figsize=(20, 10))\n    plt.plot([None] + lr_schedule + [None])\n    # X Labels\n    x = np.arange(1, epochs + 1)\n    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n    plt.xlim([1, epochs])\n    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n    \n    # Increase y-limit for better readability\n    plt.ylim([0, max(lr_schedule) * 1.1])\n    \n    # Title\n    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n    \n    # Plot Learning Rates\n    for x, val in enumerate(lr_schedule):\n        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n            if x < len(lr_schedule) - 1:\n                if lr_schedule[x - 1] < val:\n                    ha = 'right'\n                else:\n                    ha = 'left'\n            elif x == 0:\n                ha = 'right'\n            else:\n                ha = 'left'\n            plt.plot(x + 1, val, 'o', color='black');\n            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n    \n    plt.xlabel('Epoch', size=16, labelpad=5)\n    plt.ylabel('Learning Rate', size=16, labelpad=5)\n    plt.grid()\n    plt.show()\n\n# Learning rate for encoder\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\nplot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n\n# Learning Rate Callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n\n# Weight Decay Callback\n\n# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\nclass WeightDecayCallback(tf.keras.callbacks.Callback):\n    def __init__(self, wd_ratio=WD_RATIO):\n        self.step_counter = 0\n        self.wd_ratio = wd_ratio\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')\n\n# Train model on TPU!\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=f'best_{VERSION}.h5',\n    save_weights_only=True,\n    monitor='val_pF1',\n    mode='max',\n    save_best_only=True)\nhistory = model.fit(\n        train_dataset,\n        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n        validation_data = val_dataset,\n        epochs = N_EPOCHS,\n        verbose = VERBOSE,\n        callbacks = [\n            model_checkpoint_callback,\n            lr_callback,\n            WeightDecayCallback(),\n        ],\n        class_weight = {\n            0: 1.0,\n            1: 5.0,\n        },\n    )\n\n# Save model weights for inference\nmodel.save_weights(f'model_{VERSION}.h5')\n\n# F1 By Threshold\n\n# Get true labels and predictions for validation set\ny_true_val = []\ny_pred_val = []\nfor X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n    y_true_val += y_batch.numpy().tolist()\n    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()\n\n# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n# Competition Leaderboard Metric\ndef pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0\n\n# Plot pF1 by threshold plot to find best threshold\npf1_by_threshold = []\nthresholds = np.arange(0, 1.01, 0.01)\nfor t in tqdm(thresholds):\n    # Compute pF1 for each threshold\n    pf1_by_threshold.append(\n        pfbeta(y_true_val, y_pred_val > t)\n    )\n    \nplt.figure(figsize=(15,8))\nplt.title('F1 By Threshold', size=24)\nplt.plot(pf1_by_threshold, label='F1 Score')\n\n# Best threshold and pF1 score\narg_max = np.argmax(pf1_by_threshold)\nval_max = np.max(pf1_by_threshold)\nthreshold_best = thresholds[arg_max]\nplt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {threshold_best:.2f}, pF1 Score: {val_max:.2f}')\n\n# Plot pF1 by Threshold\nplt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.xlim(0, 100)\nplt.ylim(0, 1)\nplt.xlabel('Threshold')\nplt.ylabel('pF1 Score')\nplt.legend(fontsize=12)\nplt.grid()\nplt.show()\nprint(f'Best Threshold {threshold_best:.2f}.')\n\nprint(f'pF1 Score: {val_max:.2f}.')\n\n# Training History","metadata":{"execution":{"iopub.status.busy":"2023-01-25T18:52:06.279616Z","iopub.execute_input":"2023-01-25T18:52:06.279784Z","iopub.status.idle":"2023-01-25T18:52:14.930174Z","shell.execute_reply.started":"2023-01-25T18:52:06.279761Z","shell.execute_reply":"2023-01-25T18:52:14.928825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python convext_m4.py","metadata":{},"execution_count":null,"outputs":[]}]}