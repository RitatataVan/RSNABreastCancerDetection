{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#https://www.kaggle.com/competitions/rsna-breast-cancer-detection\n","#https://www.kaggle.com/datasets/pourchot/ddsm-mammography-positive-case\n","#https://www.kaggle.com/datasets/remekkinas/rsnamodules\n","#https://www.kaggle.com/code/vslaykovsky/rsna-2022-whl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:07:54.293657Z","iopub.status.busy":"2023-02-08T05:07:54.293014Z","iopub.status.idle":"2023-02-08T05:08:19.408047Z","shell.execute_reply":"2023-02-08T05:08:19.406360Z","shell.execute_reply.started":"2023-02-08T05:07:54.293527Z"},"papermill":{"duration":60.026435,"end_time":"2023-01-30T03:36:29.450678","exception":false,"start_time":"2023-01-30T03:35:29.424243","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["%%capture\n","# Source: https://www.kaggle.com/code/remekkinas/fast-dicom-processing-1-6-2x-faster?scriptVersionId=113360473\n","!pip install /kaggle/input/rsnamodules/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl \n","\n","try:\n","    import pylibjpeg\n","except:\n","   !pip install /kaggle/input/rsna-2022-whl/{pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:19.411997Z","iopub.status.busy":"2023-02-08T05:08:19.410921Z","iopub.status.idle":"2023-02-08T05:08:25.508452Z","shell.execute_reply":"2023-02-08T05:08:25.507264Z","shell.execute_reply.started":"2023-02-08T05:08:19.411941Z"},"papermill":{"duration":5.989409,"end_time":"2023-01-30T03:36:57.793249","exception":false,"start_time":"2023-01-30T03:36:51.803840","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import pylibjpeg\n","import pydicom\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from joblib import Parallel, delayed\n","from tqdm.notebook import tqdm\n","from multiprocessing import cpu_count\n","\n","import cv2\n","import glob\n","import importlib\n","import os\n","import joblib\n","import time\n","import dicomsdl\n","import gc\n","\n","# Tensorflow and CV2 set number of threads to 1 for speedup in parallell function mapping\n","tf.config.threading.set_inter_op_parallelism_threads(num_threads=1)\n","cv2.setNumThreads(1)\n","\n","# Pandas DataFrame Display Options\n","pd.options.display.max_colwidth = 99"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:25.510965Z","iopub.status.busy":"2023-02-08T05:08:25.509842Z","iopub.status.idle":"2023-02-08T05:08:31.132701Z","shell.execute_reply":"2023-02-08T05:08:31.130920Z","shell.execute_reply.started":"2023-02-08T05:08:25.510921Z"},"trusted":true},"outputs":[],"source":["filepath = sorted(glob.glob('/kaggle/input/ddsm-mammography-positive-case/DICOM/DICOM/*/*.dcm'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.136917Z","iopub.status.busy":"2023-02-08T05:08:31.136402Z","iopub.status.idle":"2023-02-08T05:08:31.165125Z","shell.execute_reply":"2023-02-08T05:08:31.164063Z","shell.execute_reply.started":"2023-02-08T05:08:31.136868Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('/kaggle/input/ddsm-mammography-positive-case/additional_train.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.167531Z","iopub.status.busy":"2023-02-08T05:08:31.166505Z","iopub.status.idle":"2023-02-08T05:08:31.184907Z","shell.execute_reply":"2023-02-08T05:08:31.183844Z","shell.execute_reply.started":"2023-02-08T05:08:31.167483Z"},"trusted":true},"outputs":[],"source":["train = train.sort_values(['patient_id']).reset_index(drop=True)\n","train['file_path'] = filepath"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.187344Z","iopub.status.busy":"2023-02-08T05:08:31.186604Z","iopub.status.idle":"2023-02-08T05:08:31.202691Z","shell.execute_reply":"2023-02-08T05:08:31.201670Z","shell.execute_reply.started":"2023-02-08T05:08:31.187302Z"},"trusted":true},"outputs":[],"source":["sum(train['patient_id'].map(lambda x:x.split('_')[-1])==train['file_path'].map(lambda x:x.split('/')[-2].split('_')[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.204461Z","iopub.status.busy":"2023-02-08T05:08:31.204076Z","iopub.status.idle":"2023-02-08T05:08:31.218692Z","shell.execute_reply":"2023-02-08T05:08:31.217650Z","shell.execute_reply.started":"2023-02-08T05:08:31.204417Z"},"trusted":true},"outputs":[],"source":["train['image_id'] = train['file_path'].map(lambda x:x.split('/')[-2].split('_')[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.220724Z","iopub.status.busy":"2023-02-08T05:08:31.219875Z","iopub.status.idle":"2023-02-08T05:08:31.406508Z","shell.execute_reply":"2023-02-08T05:08:31.405209Z","shell.execute_reply.started":"2023-02-08T05:08:31.220687Z"},"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006026,"end_time":"2023-01-30T03:36:57.806018","exception":false,"start_time":"2023-01-30T03:36:57.799992","status":"completed"},"tags":[]},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.408129Z","iopub.status.busy":"2023-02-08T05:08:31.407765Z","iopub.status.idle":"2023-02-08T05:08:31.417916Z","shell.execute_reply":"2023-02-08T05:08:31.416898Z","shell.execute_reply.started":"2023-02-08T05:08:31.408097Z"},"papermill":{"duration":0.017813,"end_time":"2023-01-30T03:36:57.831568","exception":false,"start_time":"2023-01-30T03:36:57.813755","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","\n","TARGET_HEIGHT = 1344\n","TARGET_WIDTH = 768\n","N_CHANNELS = 1\n","INPUT_SHAPE = (TARGET_HEIGHT, TARGET_WIDTH, N_CHANNELS)\n","TARGET_HEIGHT_WIDTH_RATIO = TARGET_HEIGHT / TARGET_WIDTH\n","THRESHOLD_BEST = 0.50\n","\n","CLAHE = cv2.createCLAHE(clipLimit=0.6, tileGridSize=(16, 16))\n","\n","CROP_IMAGE = True\n","APPLY_CLAHE = True\n","APPLY_EQ_HIST = False\n","\n","IMAGE_FORMAT = 'jpg'\n","IMAGE_QUALITY = 95"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005941,"end_time":"2023-01-30T03:36:57.843633","exception":false,"start_time":"2023-01-30T03:36:57.837692","status":"completed"},"tags":[]},"source":["# VOI LUT"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.422322Z","iopub.status.busy":"2023-02-08T05:08:31.421687Z","iopub.status.idle":"2023-02-08T05:08:31.432661Z","shell.execute_reply":"2023-02-08T05:08:31.431692Z","shell.execute_reply.started":"2023-02-08T05:08:31.422283Z"},"papermill":{"duration":0.017649,"end_time":"2023-01-30T03:36:57.867426","exception":false,"start_time":"2023-01-30T03:36:57.849777","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Source: https://www.kaggle.com/code/bobdegraaf/dicomsdl-voi-lut\n","def voi_lut(image, dicom):\n","    # Additional Checks\n","    if 'WindowWidth' not in dicom.getPixelDataInfo() or 'WindowWidth' not in dicom.getPixelDataInfo():\n","        return image\n","    \n","    # Load only the variables we need\n","    center = dicom['WindowCenter']\n","    width = dicom['WindowWidth']\n","    bits_stored = dicom['BitsStored']\n","    voi_lut_function = dicom['VOILUTFunction']\n","\n","    # For sigmoid it's a list, otherwise a single value\n","    if isinstance(center, list):\n","        center = center[0]\n","    if isinstance(width, list):\n","        width = width[0]\n","\n","    # Set y_min, max & range\n","    y_min = 0\n","    y_max = float(2**bits_stored - 1)\n","    y_range = y_max\n","\n","    # Function with default LINEAR (so for Nan, it will use linear)\n","    if voi_lut_function == 'SIGMOID':\n","        image = y_range / (1 + np.exp(-4 * (image - center) / width)) + y_min\n","    else:\n","        # Checks width for < 1 (in our case not necessary, always >= 750)\n","        center -= 0.5\n","        width -= 1\n","\n","        below = image <= (center - width / 2)\n","        above = image > (center + width / 2)\n","        between = np.logical_and(~below, ~above)\n","\n","        image[below] = y_min\n","        image[above] = y_max\n","        if between.any():\n","            image[between] = (\n","                ((image[between] - center) / width + 0.5) * y_range + y_min\n","            )\n","\n","    return image"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006033,"end_time":"2023-01-30T03:36:57.879586","exception":false,"start_time":"2023-01-30T03:36:57.873553","status":"completed"},"tags":[]},"source":["# Crop Image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.435411Z","iopub.status.busy":"2023-02-08T05:08:31.434572Z","iopub.status.idle":"2023-02-08T05:08:31.468593Z","shell.execute_reply":"2023-02-08T05:08:31.467264Z","shell.execute_reply.started":"2023-02-08T05:08:31.435336Z"},"papermill":{"duration":0.034876,"end_time":"2023-01-30T03:36:57.920608","exception":false,"start_time":"2023-01-30T03:36:57.885732","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Smooth vector used to smoothen sums/stds of axes\n","def smooth(l):\n","    # kernel size is 1% of vector\n","    kernel_size = int(len(l) * 0.01)\n","    kernel = np.ones(kernel_size) / kernel_size\n","    return np.convolve(l, kernel, mode='same')\n","\n","# X Crop offset based on first column with sum below 5% of maximum column sums*std\n","def get_x_offset(image, max_col_sum_ratio_threshold=0.05, debug=None):\n","    # Image Dimensions\n","    H, W = image.shape\n","    # Percentual margin added to offset\n","    margin = int(image.shape[1] * 0.00)\n","    # Threshold values based on smoothed sum x std to capture varying intensity columns\n","    vv = smooth(image.sum(axis=0).squeeze()) * smooth(image.std(axis=0).squeeze())\n","    # Find maximum sum in first 75% of columns\n","    vv_argmax = vv[:int(image.shape[1] * 0.75)].argmax()\n","    # Threshold value\n","    vv_threshold = vv.max() * max_col_sum_ratio_threshold\n","    \n","    # Find first column after maximum column below threshold value\n","    for offset, v in enumerate(vv):\n","        # Start searching from vv_argmax\n","        if offset < vv_argmax:\n","            continue\n","        \n","        # Column below threshold value found\n","        if v < vv_threshold:\n","            offset = min(W, offset + margin)\n","            break\n","            \n","    if isinstance(debug, np.ndarray):\n","        debug[1].imshow(image)\n","        debug[1].set_title('X Offset')\n","        vv_scale = H / vv.max() * 0.90\n","        # Values\n","        debug[1].plot(H - vv * vv_scale , c='red', label='vv')\n","        # Threshold\n","        debug[1].hlines(H - vv_threshold * vv_scale, 0, W -1, colors='orange', label='threshold')\n","        # Max Value\n","        debug[1].scatter(vv_argmax, H - vv[vv_argmax] * vv_scale, c='blue', s=100, label='Max', zorder=np.PINF)\n","        # First Column Below Threshold\n","        debug[1].scatter(offset, H - vv[offset] * vv_scale, c='purple', s=100, label='Offset', zorder=np.PINF)\n","        debug[1].set_ylim(H, 0)\n","        debug[1].legend()\n","        debug[1].axis('off')\n","        \n","    return offset\n","\n","# Y Crop offset based on first bottom and top rows with sum below 10% of maximum row sum*std\n","def get_y_offsets(image, max_row_sum_ratio_threshold=0.05, debug=None):\n","    # Image Dimensions\n","    H, W = image.shape\n","    # Margin to add to offsets\n","    margin = 0\n","    # Threshold values based on smoothed sum x std to capture varying intensity columns\n","    vv = smooth(image.sum(axis=1).squeeze()) * smooth(image.std(axis=1).squeeze())\n","    # Find maximum sum * std row in inter quartile rows\n","    vv_argmax = int(image.shape[0] * 0.25) + vv[int(image.shape[0] * 0.25):int(image.shape[0] * 0.75)].argmax()\n","    # Threshold value\n","    vv_threshold = vv.max() * max_row_sum_ratio_threshold\n","    # Default crop offsets\n","    offset_bottom = 0\n","    offset_top = H\n","\n","    # Bottom offset, search from argmax to bottom\n","    for offset in reversed(range(0, vv_argmax)):\n","        v = vv[offset]\n","        if v < vv_threshold:\n","            offset_bottom = offset\n","            break\n","    \n","    if isinstance(debug, np.ndarray):\n","        debug[2].imshow(image)\n","        debug[2].set_title('Y Bottom Offset')\n","        vv_scale = W / vv.max() * 0.90\n","        # Values\n","        debug[2].plot(vv * vv_scale, np.arange(H), c='red', label='vv')\n","        # Threshold\n","        debug[2].vlines(vv_threshold * vv_scale, 0, H -1, colors='orange', label='threshold')\n","        # Max Value\n","        debug[2].scatter(vv[vv_argmax] * vv_scale, vv_argmax, c='blue', s=100, label='Max', zorder=np.PINF)\n","        # First Column Below Threshold\n","        debug[2].scatter(vv[offset_bottom] * vv_scale, offset_bottom, c='purple', s=100, label='Offset', zorder=np.PINF)\n","        debug[2].set_ylim(H, 0)\n","        debug[2].legend()\n","        debug[2].axis('off')\n","            \n","    # Top offset, search from argmax to top\n","    for offset in range(vv_argmax, H):\n","        v = vv[offset]\n","        if v < vv_threshold:\n","            offset_top = offset\n","            break\n","            \n","    if isinstance(debug, np.ndarray):\n","        debug[3].imshow(image)\n","        debug[3].set_title('Y Top Offset')\n","        vv_scale = W / vv.max() * 0.90\n","        # Values\n","        debug[3].plot(vv * vv_scale, np.arange(H) , c='red', label='vv')\n","        # Threshold\n","        debug[3].vlines(vv_threshold * vv_scale, 0, H -1, colors='orange', label='threshold')\n","        # Max Value\n","        debug[3].scatter(vv[vv_argmax] * vv_scale, vv_argmax, c='blue', s=100, label='Max', zorder=np.PINF)\n","        # First Column Below Threshold\n","        debug[3].scatter(vv[offset_top] * vv_scale, offset_top, c='purple', s=100, label='Offset', zorder=np.PINF)\n","        debug[2].set_ylim(H, 0)\n","        debug[3].legend()\n","        debug[3].axis('off')\n","            \n","    return max(0, offset_bottom - margin), min(image.shape[0], offset_top + margin)\n","\n","# Crop image and pad offsets to target image height/width ratio to preserve information\n","def crop(image, size=None, debug=False):\n","    # Image dimensions\n","    H, W = image.shape\n","    # Compute x/bottom/top offsets\n","    x_offset = get_x_offset(image, debug=debug)\n","    offset_bottom, offset_top = get_y_offsets(image[:,:x_offset], debug=debug)\n","    # Crop Height and Width\n","    h_crop = offset_top - offset_bottom\n","    w_crop = x_offset\n","    \n","    # Pad crop offsets to target aspect ratio\n","    if size is not None:\n","        # Height too large, pad x offset\n","        if (h_crop / w_crop) > TARGET_HEIGHT_WIDTH_RATIO:\n","            x_offset += int(h_crop / TARGET_HEIGHT_WIDTH_RATIO - w_crop)\n","        else:\n","            # Height too small, pad bottom/top offsets\n","            offset_bottom -= int(0.50 * (w_crop * TARGET_HEIGHT_WIDTH_RATIO - h_crop))\n","            offset_bottom_correction = max(0, -offset_bottom)\n","            offset_bottom += offset_bottom_correction\n","\n","            offset_top += int(0.50 * (w_crop * TARGET_HEIGHT_WIDTH_RATIO - h_crop))\n","            offset_top += offset_bottom_correction\n","        \n","    # Crop Image\n","    image = image[offset_bottom:offset_top:,:x_offset]\n","        \n","    return image"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005918,"end_time":"2023-01-30T03:36:57.932570","exception":false,"start_time":"2023-01-30T03:36:57.926652","status":"completed"},"tags":[]},"source":["# Process Image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.471170Z","iopub.status.busy":"2023-02-08T05:08:31.470517Z","iopub.status.idle":"2023-02-08T05:08:31.488070Z","shell.execute_reply":"2023-02-08T05:08:31.487171Z","shell.execute_reply.started":"2023-02-08T05:08:31.471124Z"},"papermill":{"duration":0.023071,"end_time":"2023-01-30T03:36:57.961787","exception":false,"start_time":"2023-01-30T03:36:57.938716","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# based on: https://www.kaggle.com/code/remekkinas/fast-dicom-processing-1-6-2x-faster?scriptVersionId=113360473\n","def process(file_path, size=None, dicom_process=True, ret_target=False, crop_image=False, apply_clahe=APPLY_CLAHE, apply_eq_hist=APPLY_EQ_HIST, debug=False):\n","    # Read Dicom File\n","    dicom = dicomsdl.open(file_path)\n","    image = dicom.pixelData()\n","    \n","    # Save original image for debug purposes\n","    if debug:\n","        fig, axes = plt.subplots(1, 5, figsize=(20,10))\n","        image0 = np.copy(image)\n","        axes[0].imshow(image0)\n","        axes[0].set_title('Original Image')\n","        axes[0].axis('off')\n","    else:\n","        axes = False\n","        \n","    try:\n","        image = voi_lut(image, dicom)\n","    except:\n","        pass\n","\n","    # Normalize [0,1] range\n","    image = (image - image.min()) / (image.max() - image.min())\n","\n","    # Convert to uint8 image in range [0, 255]\n","    image = (image * 255).astype(np.uint8)\n","    \n","    # Normalize to left/right orientation by flipping right/left oriented images\n","    h0, w0 = image.shape\n","    if image[:,int(-w0 * 0.10):].sum() > image[:,:int(w0 * 0.10)].sum():\n","        image = np.flip(image, axis=1)\n","    \n","    if crop_image:\n","        image = crop(image, size=size, debug=axes)\n","    \n","    # Resize\n","    if size is not None:\n","        # Pad black pixels to get correct image ratios\n","        h, w = image.shape\n","        if (h / w) > TARGET_HEIGHT_WIDTH_RATIO:\n","            pad = int(h / TARGET_HEIGHT_WIDTH_RATIO - w)\n","            image = np.pad(image, [[0,0], [0, pad]])\n","            h, w = image.shape\n","        else:\n","            pad = int(0.50 * (w * TARGET_HEIGHT_WIDTH_RATIO - h))\n","            image = np.pad(image, [[pad, pad], [0,0]])\n","            h, w = image.shape\n","        # Resize\n","        image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n","        \n","    # Apply CLAHE contrast enhancement\n","    # https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html\n","    #if apply_clahe:\n","    #    image = CLAHE.apply(image)\n","        \n","    # Apply Histogram Equalization\n","    # https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html\n","    if apply_eq_hist:\n","        image = cv2.equalizeHist(image)\n","        \n","    if debug:\n","        axes[4].imshow(image)\n","        axes[4].set_title('Processed Image')\n","        axes[4].axis('off')\n","        plt.show()\n","\n","    # Return Cancer Target\n","    if ret_target:\n","        #patient_id = int(file_path.split('/')[-2])\n","        #image_id = int(file_path.split('/')[-1].split('.')[0])\n","\n","        target = 1\n","        \n","        return image, target\n","    # Return image Only\n","    else:\n","        if debug:\n","            return image0, image\n","        else:\n","            return image"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005944,"end_time":"2023-01-30T03:36:57.973880","exception":false,"start_time":"2023-01-30T03:36:57.967936","status":"completed"},"tags":[]},"source":["# Example Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:31.489517Z","iopub.status.busy":"2023-02-08T05:08:31.489176Z","iopub.status.idle":"2023-02-08T05:08:56.211610Z","shell.execute_reply":"2023-02-08T05:08:56.210362Z","shell.execute_reply.started":"2023-02-08T05:08:31.489488Z"},"papermill":{"duration":29.981235,"end_time":"2023-01-30T03:37:28.494958","exception":false,"start_time":"2023-01-30T03:36:58.513723","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["N = 4 if IS_INTERACTIVE else 10\n","for fp in tqdm(train['file_path'].head(N)):\n","    process(\n","            fp,\n","            crop_image=True,\n","            size=(TARGET_WIDTH, TARGET_HEIGHT),\n","            debug=True,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:56.213267Z","iopub.status.busy":"2023-02-08T05:08:56.212906Z","iopub.status.idle":"2023-02-08T05:08:56.922254Z","shell.execute_reply":"2023-02-08T05:08:56.921173Z","shell.execute_reply.started":"2023-02-08T05:08:56.213233Z"},"trusted":true},"outputs":[],"source":["# Make Pairs of Views as input to the model\n","FILE_PATHS_PAIRS = []\n","for row_idx, row in tqdm(train.iterrows(), total=len(train)):\n","        FILE_PATHS_PAIRS.append(row[['patient_id', 'image_id']].values)\n","        \n","FILE_PATHS_PAIRS = np.array(FILE_PATHS_PAIRS, dtype=object)\n","print(f'FILE_PATHS_PAIRS shape: {FILE_PATHS_PAIRS.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:56.923935Z","iopub.status.busy":"2023-02-08T05:08:56.923616Z","iopub.status.idle":"2023-02-08T05:08:56.931028Z","shell.execute_reply":"2023-02-08T05:08:56.929885Z","shell.execute_reply.started":"2023-02-08T05:08:56.923905Z"},"trusted":true},"outputs":[],"source":["FILE_PATHS_PAIRS"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:56.933174Z","iopub.status.busy":"2023-02-08T05:08:56.932712Z","iopub.status.idle":"2023-02-08T05:08:56.944535Z","shell.execute_reply":"2023-02-08T05:08:56.943335Z","shell.execute_reply.started":"2023-02-08T05:08:56.933123Z"},"trusted":true},"outputs":[],"source":["# Put every image in a seperate TFRecord file\n","N_CHUNKS = 13\n","CHUNKS = np.array_split(FILE_PATHS_PAIRS, N_CHUNKS)\n","\n","print(f'N_CHUNKS: {N_CHUNKS}, CHUNK len: {len(CHUNKS[0])}, shape: {CHUNKS[0].shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:56.946773Z","iopub.status.busy":"2023-02-08T05:08:56.946200Z","iopub.status.idle":"2023-02-08T05:08:56.958011Z","shell.execute_reply":"2023-02-08T05:08:56.956835Z","shell.execute_reply.started":"2023-02-08T05:08:56.946728Z"},"trusted":true},"outputs":[],"source":["# Single sample processing\n","def process_chunk(args):\n","    patient_id, image_id = args\n","    # Define file path\n","\n","    fp = glob.glob(f'/kaggle/input/ddsm-mammography-positive-case/DICOM/DICOM/{patient_id}_{image_id}/*.dcm')[0]\n","    # Get processed image and target\n","    image, target = process(fp, size=(TARGET_WIDTH, TARGET_HEIGHT), ret_target=True, crop_image=True)\n","\n","    # Make grayscale channel\n","    image = np.expand_dims(image, 2)\n","    \n","    # Encode PNG\n","    if IMAGE_FORMAT == 'PNG':\n","        image_serialized = tf.io.encode_png(image, compression=9).numpy()\n","    # Encode JPEG\n","    else:\n","        image_serialized = tf.io.encode_jpeg(image, quality=IMAGE_QUALITY, optimize_size=True).numpy()\n","    \n","    return image_serialized, target, int(patient_id.split('_')[-1]), int(image_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:08:56.960055Z","iopub.status.busy":"2023-02-08T05:08:56.959706Z","iopub.status.idle":"2023-02-08T05:10:52.011046Z","shell.execute_reply":"2023-02-08T05:10:52.008863Z","shell.execute_reply.started":"2023-02-08T05:08:56.960024Z"},"trusted":true},"outputs":[],"source":["def to_tf_records(chunks):\n","    for chunk_idx, chunk in enumerate(tqdm(chunks)):\n","        print(f'===== GENERATING TFRECORDS {chunk_idx} =====')\n","        tfrecord_name = f'batch_{chunk_idx}.tfrecords'\n","        \n","        # Create the actual TFRecords\n","        options = tf.io.TFRecordOptions(compression_type='GZIP', compression_level=9)\n","        with tf.io.TFRecordWriter(tfrecord_name, options=options) as file_writer:\n","            # Process Samples in Chunk in Parallell\n","            jobs = [joblib.delayed(process_chunk)(args) for args in chunk]\n","            chunk_processed = joblib.Parallel(\n","                n_jobs=cpu_count(),\n","                verbose=0,\n","                backend='multiprocessing',\n","                prefer='threads',\n","            )(jobs)\n","            \n","            # Add Processed Samples to TFRecord\n","            for image, target, patient_id, image_id in chunk_processed:\n","                record_bytes = tf.train.Example(features=tf.train.Features(feature={\n","                    # Image\n","                    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n","\n","                    # target\n","                    'target': tf.train.Feature(int64_list=tf.train.Int64List(value=[target])),\n","                    \n","                    # patient_id\n","                    'patient_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[patient_id])),\n","                    \n","                    # image_id\n","                    'image_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[image_id])),\n","                })).SerializeToString()\n","                file_writer.write(record_bytes)\n","            \n","# Create TFRecords\n","if IS_INTERACTIVE:\n","    to_tf_records(CHUNKS[:1])\n","else:\n","    to_tf_records(CHUNKS)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:10:52.014505Z","iopub.status.busy":"2023-02-08T05:10:52.013822Z","iopub.status.idle":"2023-02-08T05:10:52.023566Z","shell.execute_reply":"2023-02-08T05:10:52.022398Z","shell.execute_reply.started":"2023-02-08T05:10:52.014435Z"},"trusted":true},"outputs":[],"source":["N = 16 if IS_INTERACTIVE else 32"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:10:52.026054Z","iopub.status.busy":"2023-02-08T05:10:52.025670Z","iopub.status.idle":"2023-02-08T05:10:52.041553Z","shell.execute_reply":"2023-02-08T05:10:52.039677Z","shell.execute_reply.started":"2023-02-08T05:10:52.026019Z"},"trusted":true},"outputs":[],"source":["# Function to decode the TFRecords\n","def decode_tfrecord(record_bytes):\n","    features = tf.io.parse_single_example(record_bytes, {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'target': tf.io.FixedLenFeature([], tf.int64),\n","        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n","        'image_id': tf.io.FixedLenFeature([], tf.int64),\n","    })\n","        \n","    if IMAGE_FORMAT == 'PNG':\n","        image = tf.io.decode_png(features['image'], channels=N_CHANNELS)\n","    else:\n","        image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n","        \n","    image = tf.reshape(image, [TARGET_HEIGHT, TARGET_WIDTH, N_CHANNELS])\n","\n","    target = features['target']\n","    patient_id = features['patient_id']\n","    image_id = features['image_id']\n","    \n","    return image, target, patient_id, image_id"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:10:52.043842Z","iopub.status.busy":"2023-02-08T05:10:52.043399Z","iopub.status.idle":"2023-02-08T05:10:52.062125Z","shell.execute_reply":"2023-02-08T05:10:52.061003Z","shell.execute_reply.started":"2023-02-08T05:10:52.043786Z"},"trusted":true},"outputs":[],"source":["# Sample TFRecord Dataset\n","def get_train_dataset():\n","    # Read all TFRecord file paths\n","    FNAMES_TRAIN_TFRECORDS = tf.io.gfile.glob('./*.tfrecords')\n","    # initialize TFRecord dataset\n","    train_dataset = tf.data.TFRecordDataset(FNAMES_TRAIN_TFRECORDS, num_parallel_reads=1, compression_type='GZIP')\n","    # Decode samples by mapping with decode function\n","    train_dataset = train_dataset.map(decode_tfrecord)\n","    # Batch samples\n","    train_dataset = train_dataset.batch(N)\n","    \n","    return train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:10:52.065074Z","iopub.status.busy":"2023-02-08T05:10:52.064310Z","iopub.status.idle":"2023-02-08T05:10:52.077432Z","shell.execute_reply":"2023-02-08T05:10:52.076299Z","shell.execute_reply.started":"2023-02-08T05:10:52.065025Z"},"trusted":true},"outputs":[],"source":["# Shows a batch of images\n","def show_batch(dataset, rows=N, cols=1):\n","    images, targets, patient_ids, image_ids = next(iter(dataset))\n","    images = np.moveaxis(images, 3, 1)\n","    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6, rows*10))\n","    for r in range(rows):\n","        for c in range(cols):\n","            img = images[r,c]\n","            axes[r].imshow(img)\n","            if c == 0:\n","                target = targets[r]\n","                patient_id = patient_ids[r]\n","                image_id = image_ids[r]\n","                axes[r].set_title(f'target: {target}, patient_id: {patient_id}, image_id: {image_id}', fontsize=12, pad=16)\n","        \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-08T05:10:52.080148Z","iopub.status.busy":"2023-02-08T05:10:52.079344Z","iopub.status.idle":"2023-02-08T05:10:57.310223Z","shell.execute_reply":"2023-02-08T05:10:57.308687Z","shell.execute_reply.started":"2023-02-08T05:10:52.080086Z"},"trusted":true},"outputs":[],"source":["# Show Example Batch\n","train_dataset = get_train_dataset()\n","show_batch(train_dataset)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
